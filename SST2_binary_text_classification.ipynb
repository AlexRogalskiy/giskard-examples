{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![giskard_logo.png](https://raw.githubusercontent.com/Giskard-AI/giskard/main/readme/Logo_full_darkgreen.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing giskard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect the external worker in daemon mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%giskard` not found.\n"
     ]
    }
   ],
   "source": [
    "%giskard worker start -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-1.13.1-cp38-cp38-manylinux1_x86_64.whl (887.4 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from torch) (4.4.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Requirement already satisfied: setuptools in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\n",
      "Requirement already satisfied: wheel in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
      "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (1.13.1)\n",
      "Collecting torchdata\n",
      "  Using cached torchdata-0.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Collecting torchtext\n",
      "  Using cached torchtext-0.14.1-cp38-cp38-manylinux1_x86_64.whl (2.0 MB)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: wheel in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\n",
      "Requirement already satisfied: requests in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from torchdata) (2.28.1)\n",
      "Collecting portalocker>=2.0.0\n",
      "  Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: urllib3>=1.25 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from torchdata) (1.26.13)\n",
      "Requirement already satisfied: tqdm in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from torchtext) (4.64.1)\n",
      "Requirement already satisfied: numpy in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from torchtext) (1.21.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from requests->torchdata) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from requests->torchdata) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from requests->torchdata) (3.4)\n",
      "Installing collected packages: portalocker, torchtext, torchdata\n",
      "Successfully installed portalocker-2.7.0 torchdata-0.5.1 torchtext-0.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchdata torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.07M/5.07M [00:00<00:00, 43.8MB/s]\n",
      "Downloading: \"https://download.pytorch.org/models/text/xlmr.vocab.pt\" to /home/gitpod/.cache/torch/hub/checkpoints/xlmr.vocab.pt\n",
      "100%|██████████| 4.85M/4.85M [00:00<00:00, 123MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torchtext.transforms as T\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "padding_idx = 1\n",
    "bos_idx = 0\n",
    "eos_idx = 2\n",
    "max_seq_len = 256\n",
    "xlmr_vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\n",
    "xlmr_spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\n",
    "\n",
    "text_transform = T.Sequential(\n",
    "    T.SentencePieceTokenizer(xlmr_spm_model_path),\n",
    "    T.VocabTransform(load_state_dict_from_url(xlmr_vocab_path)),\n",
    "    T.Truncate(max_seq_len - 2),\n",
    "    T.AddToken(token=bos_idx, begin=True),\n",
    "    T.AddToken(token=eos_idx, begin=False),\n",
    ")\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import SST2\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_datapipe = SST2(split=\"train\")\n",
    "dev_datapipe = SST2(split=\"dev\")\n",
    "\n",
    "\n",
    "# Transform the raw dataset using non-batched API (i.e apply transformation line by line)\n",
    "def apply_transform(x):\n",
    "    return text_transform(x[0]), x[1]\n",
    "\n",
    "dev_dataframe=pd.DataFrame(dev_datapipe, columns=[\"text\", \"label\"])\n",
    "train_dataframe=pd.DataFrame(train_datapipe, columns=[\"text\", \"label\"])\n",
    "\n",
    "train_datapipe = train_datapipe.map(apply_transform)\n",
    "train_datapipe = train_datapipe.batch(batch_size)\n",
    "train_datapipe = train_datapipe.rows2columnar([\"token_ids\", \"target\"])\n",
    "train_dataloader = DataLoader(train_datapipe, batch_size=None)\n",
    "\n",
    "dev_datapipe = dev_datapipe.map(apply_transform)\n",
    "dev_datapipe = dev_datapipe.batch(batch_size)\n",
    "dev_datapipe = dev_datapipe.rows2columnar([\"token_ids\", \"target\"])\n",
    "dev_dataloader = DataLoader(dev_datapipe, batch_size=None)\n",
    "#print(list(dev_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/text/xlmr.base.encoder.pt\" to /home/gitpod/.cache/torch/hub/checkpoints/xlmr.base.encoder.pt\n",
      "100%|██████████| 1.03G/1.03G [01:06<00:00, 16.6MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (encoder): RobertaEncoder(\n",
       "    (transformer): TransformerEncoder(\n",
       "      (token_embedding): Embedding(250002, 768, padding_idx=1)\n",
       "      (layers): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (6): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (7): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (8): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (9): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (10): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (11): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (positional_embedding): PositionalEmbedding(\n",
       "        (embedding): Embedding(514, 768, padding_idx=1)\n",
       "      )\n",
       "      (embedding_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (head): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "    (activation_fn): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "input_dim = 768\n",
    "\n",
    "from torchtext.models import RobertaClassificationHead, XLMR_BASE_ENCODER\n",
    "\n",
    "classifier_head = RobertaClassificationHead(num_classes=num_classes, input_dim=input_dim)\n",
    "model = XLMR_BASE_ENCODER.get_model(head=classifier_head)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext.functional as F\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 1e-5\n",
    "optim = AdamW(model.parameters(), lr=learning_rate)\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def train_step(input, target):\n",
    "    output = model(input)\n",
    "    loss = criteria(output, target)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "\n",
    "def eval_step(input, target):\n",
    "    output = model(input)\n",
    "    loss = criteria(output, target).item()\n",
    "    return float(loss), (output.argmax(1) == target).type(torch.float).sum().item()\n",
    "\n",
    "def eval_step1(input, target):\n",
    "    output = model(input)\n",
    "    #(output.argmax(1) == target).type(torch.int)\n",
    "    return output\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dev_dataloader:\n",
    "            input = F.to_tensor(batch[\"token_ids\"], padding_value=padding_idx).to(DEVICE)\n",
    "            target = torch.tensor(batch[\"target\"]).to(DEVICE)\n",
    "            loss, predictions = eval_step(input, target)\n",
    "            total_loss += loss\n",
    "            correct_predictions += predictions\n",
    "            total_predictions += len(target)\n",
    "            counter += 1\n",
    "\n",
    "    return total_loss / counter, correct_predictions / total_predictions\n",
    "\n",
    "def evaluate1():\n",
    "    model.eval() \n",
    "    temp=torch.empty((16,2))\n",
    "    i=1\n",
    "    with torch.no_grad():\n",
    "        for batch in dev_dataloader:\n",
    "            input = F.to_tensor(batch[\"token_ids\"], padding_value=padding_idx).to(DEVICE)\n",
    "            target = torch.tensor(batch[\"target\"]).to(DEVICE)\n",
    "            predictions = eval_step1(input, target)\n",
    "            np_arr = predictions.cpu().detach().numpy()\n",
    "        \n",
    "            if(i==1):\n",
    "                temp=temp+np_arr\n",
    "                i=i-1\n",
    "            else:\n",
    "                temp=np.concatenate((temp,np_arr),axis=0)\n",
    "            \n",
    "              \n",
    "            \n",
    "    \n",
    "    return  temp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dev(df):\n",
    "    pred=evaluate1()\n",
    "    print(\"Final\")\n",
    "    print(pred)\n",
    "    return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ibatch= 1 time = 12.36302137374878\n",
      "ibatch= 2 time = 9.453430652618408\n",
      "ibatch= 3 time = 9.110814571380615\n",
      "ibatch= 4 time = 10.140874862670898\n",
      "ibatch= 5 time = 7.332277536392212\n",
      "ibatch= 6 time = 8.414839506149292\n",
      "ibatch= 7 time = 12.236357688903809\n",
      "ibatch= 8 time = 8.4411141872406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages/torch/nn/modules/transformer.py:276: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:175.)\n",
      "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = [0], loss = [0.6928948933427984], accuracy = [0.5103211009174312]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "max_entries = 8\n",
    "import time\n",
    "for e in range(num_epochs):\n",
    "    for ibatch, batch in enumerate(train_dataloader):\n",
    "        start = time.time()\n",
    "        input = F.to_tensor(batch[\"token_ids\"], padding_value=padding_idx).to(DEVICE)\n",
    "        target = torch.tensor(batch[\"target\"]).to(DEVICE)\n",
    "        train_step(input, target)\n",
    "        ibatch+=1\n",
    "        print(\"ibatch=\",ibatch, \"time =\", time.time() - start)\n",
    "        if ibatch==max_entries:\n",
    "            break\n",
    "\n",
    "    loss, accuracy = evaluate()\n",
    "    print(\"Epoch = [{}], loss = [{}], accuracy = [{}]\".format(e, loss, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from giskard import GiskardClient\n",
    "\n",
    "url = \"http://localhost:19000\"\n",
    "token = \"eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJhZG1pbiIsInRva2VuX3R5cGUiOiJBUEkiLCJhdXRoIjoiUk9MRV9BRE1JTiIsImV4cCI6MTY4MjkzMzAxMH0.C3desk4saD8pu9gRrl-faqouXaGiOxbjTU_yWctMvv4\"\n",
    "client = GiskardClient(url, token)\n",
    "\n",
    "text = client.create_project(\"tuned_text_classification\", \"Text_Classification\", \"Project to classify finetuned text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_types = {'text':\"text\",\n",
    "               'label':\"category\"}\n",
    "\n",
    "classification_label =['0', '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final\n",
      "[[0.1746946  0.20137133]\n",
      " [0.18500453 0.2066888 ]\n",
      " [0.18448675 0.20467065]\n",
      " ...\n",
      " [0.18144989 0.20699657]\n",
      " [0.17409202 0.20786889]\n",
      " [0.1843352  0.2043485 ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid prediction_function parameter: [[0.1746946  0.20137133]\n [0.18500453 0.2066888 ]\n [0.18448675 0.20467065]\n ...\n [0.18144989 0.20699657]\n [0.17409202 0.20786889]\n [0.1843352  0.2043485 ]]. Please specify Python function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m text\u001b[39m.\u001b[39;49mupload_model_and_df(\n\u001b[1;32m      2\u001b[0m     prediction_function\u001b[39m=\u001b[39;49m predict_dev(dev_dataframe),\n\u001b[1;32m      3\u001b[0m     model_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mclassification\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     df\u001b[39m=\u001b[39;49mdev_dataframe,\n\u001b[1;32m      5\u001b[0m     column_types\u001b[39m=\u001b[39;49mcolumn_types,\n\u001b[1;32m      6\u001b[0m     target\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m# The column name in df corresponding to the actual target variable (ground truth).\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m     feature_names\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m# List of the feature names of prediction_function\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m     model_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrained_data\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m# Name of the model\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m     dataset_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msst2_data\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m# Name of the dataset\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m     classification_labels\u001b[39m=\u001b[39;49mclassification_label\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/lib/python3.8/site-packages/giskard/client/project.py:391\u001b[0m, in \u001b[0;36mGiskardProject.upload_model_and_df\u001b[0;34m(self, prediction_function, model_type, df, column_types, feature_names, target, model_name, dataset_name, classification_threshold, classification_labels)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manalytics\u001b[39m.\u001b[39mtrack(\u001b[39m\"\u001b[39m\u001b[39mUpload model and dataset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    390\u001b[0m data, raw_column_types \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_and_compress_data(column_types, df, target)\n\u001b[0;32m--> 391\u001b[0m classification_labels, model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_model(\n\u001b[1;32m    392\u001b[0m     classification_labels,\n\u001b[1;32m    393\u001b[0m     classification_threshold,\n\u001b[1;32m    394\u001b[0m     feature_names,\n\u001b[1;32m    395\u001b[0m     model_type,\n\u001b[1;32m    396\u001b[0m     prediction_function,\n\u001b[1;32m    397\u001b[0m     target,\n\u001b[1;32m    398\u001b[0m     df,\n\u001b[1;32m    399\u001b[0m )\n\u001b[1;32m    400\u001b[0m data_res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_data(column_types, data, dataset_name, raw_column_types, target)\n\u001b[1;32m    401\u001b[0m model_res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_model(\n\u001b[1;32m    402\u001b[0m     classification_labels,\n\u001b[1;32m    403\u001b[0m     classification_threshold,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m     model_name,\n\u001b[1;32m    408\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/lib/python3.8/site-packages/giskard/client/project.py:229\u001b[0m, in \u001b[0;36mGiskardProject._validate_model\u001b[0;34m(self, classification_labels, classification_threshold, feature_names, model_type, prediction_function, target, validate_df)\u001b[0m\n\u001b[1;32m    224\u001b[0m prediction_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_model_is_pickleable(prediction_function)\n\u001b[1;32m    225\u001b[0m transformed_pred_func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_prediction_function(\n\u001b[1;32m    226\u001b[0m     prediction_function, feature_names\n\u001b[1;32m    227\u001b[0m )\n\u001b[0;32m--> 229\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_prediction_function(prediction_function)\n\u001b[1;32m    230\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_model_type(model_type)\n\u001b[1;32m    231\u001b[0m classification_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_classification_labels(\n\u001b[1;32m    232\u001b[0m     classification_labels, model_type\n\u001b[1;32m    233\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/lib/python3.8/site-packages/giskard/client/project.py:444\u001b[0m, in \u001b[0;36mGiskardProject._validate_prediction_function\u001b[0;34m(prediction_function)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    442\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_prediction_function\u001b[39m(prediction_function):\n\u001b[1;32m    443\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(prediction_function):\n\u001b[0;32m--> 444\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    445\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid prediction_function parameter: \u001b[39m\u001b[39m{\u001b[39;00mprediction_function\u001b[39m}\u001b[39;00m\u001b[39m. Please specify Python function.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid prediction_function parameter: [[0.1746946  0.20137133]\n [0.18500453 0.2066888 ]\n [0.18448675 0.20467065]\n ...\n [0.18144989 0.20699657]\n [0.17409202 0.20786889]\n [0.1843352  0.2043485 ]]. Please specify Python function."
     ]
    }
   ],
   "source": [
    "text.upload_model_and_df(\n",
    "    prediction_function= predict_dev(dev_dataframe),\n",
    "    model_type='classification',\n",
    "    df=dev_dataframe,\n",
    "    column_types=column_types,\n",
    "    target='label', # The column name in df corresponding to the actual target variable (ground truth).\n",
    "    feature_names=['text'], # List of the feature names of prediction_function\n",
    "    model_name='trained_data', # Name of the model\n",
    "    dataset_name='sst2_data', # Name of the dataset\n",
    "    classification_labels=classification_label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully uploaded to project key 'tuned_text_classification' with ID = 78. It is available at http://localhost:19000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "text.upload_df(\n",
    "    df=train_dataframe, # The dataset you want to upload\n",
    "    column_types=column_types, # All the column types without the target\n",
    "    name=\"train_data\"  # Name of the dataset\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 (default, Jan 10 2023, 15:23:34) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
