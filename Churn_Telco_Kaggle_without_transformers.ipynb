{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pvKxJjsNSoE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![giskard_logo.png](https://raw.githubusercontent.com/Giskard-AI/giskard/main/readme/Logo_full_darkgreen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a9b17467105f4031a3f9eae70ef4138f",
    "deepnote_cell_height": 134,
    "deepnote_cell_type": "markdown",
    "id": "PKcOi3D37xbW",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# About Giskard\n",
    "\n",
    "Open-Source CI/CD platform for ML teams. Deliver ML products, better & faster. \n",
    "\n",
    "*   Collaborate faster with feedback from business stakeholders.\n",
    "*   Deploy automated tests to eliminate regressions, errors & biases.\n",
    "\n",
    "üè° [Website](https://giskard.ai/)\n",
    "\n",
    "üìó [Documentation](https://docs.giskard.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f35c8e8d3fbf4c0f9c01a69673c318a1",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 6
    },
    "deepnote_cell_height": 110,
    "deepnote_cell_type": "markdown",
    "id": "mJTqM-W_7xbW",
    "owner_user_id": "41ec0844-b5b7-49c2-9460-710a452f98de",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Telco custormer churn data\n",
    "\n",
    "This notebook is based on:\n",
    "- [medium article](https://towardsdatascience.com/end-to-end-machine-learning-project-telco-customer-churn-90744a8df97d)\n",
    "- [Kaggle dataset](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)\n",
    "- [Giskard credit scoring example](https://github.com/Giskard-AI/examples/blob/main/Credit%20scoring%20classification%20model.ipynb) (mainly cells that import models into giskard for inspection)\n",
    "\n",
    "In which we will explore how to predict customer churn, a critical factor for telecommunication companies to be able to effectively retain customers. \n",
    "\n",
    "We will follow the same steps of the notebook displayed in [medium article](https://towardsdatascience.com/end-to-end-machine-learning-project-telco-customer-churn-90744a8df97d), adding when needed the functions needed to inspect the model in Giskard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e8d609f32d5243dd917cc3104599b8d8",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 12
    },
    "deepnote_cell_height": 230,
    "deepnote_cell_type": "markdown",
    "id": "WNI85koE7xbX",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## 1. Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import telecom dataset into a pandas data frame\n",
    "df_telco = pd.read_csv('datasets/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# check unique values of each column\n",
    "#for column in df_telco.columns:\n",
    "#    print('Column: {} - Unique Values: {}'.format(column, df_telco[column].unique()))\n",
    "\n",
    "# summary of the data frame\n",
    "#df_telco.info()\n",
    "\n",
    "# transform the column TotalCharges into a numeric data type\n",
    "df_telco['TotalCharges'] = pd.to_numeric(df_telco['TotalCharges'], errors='coerce')\n",
    "\n",
    "# drop observations with null values\n",
    "df_telco.dropna(inplace=True)\n",
    "\n",
    "# drop the customerID column from the dataset\n",
    "df_telco.drop(columns='customerID', inplace=True)\n",
    "\n",
    "# remove (automatic) from payment method names\n",
    "df_telco['PaymentMethod'] = df_telco['PaymentMethod'].str.replace(' (automatic)', '', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering (manual, without sklearn transformers)\n",
    "\n",
    "The next cell is taken as is from [medium article](https://towardsdatascience.com/end-to-end-machine-learning-project-telco-customer-churn-90744a8df97d), where the data transformations are written manually. In this notebook, we're going to wrap these transformation inside a `predict` function instead of redefining the transformations in terms of sklearn pre-defined ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_telco_transformed = df_telco.copy()\n",
    "\n",
    "# label encoding (binary variables)\n",
    "label_encoding_columns = ['gender', 'Partner', 'Dependents', 'PaperlessBilling', 'PhoneService', 'Churn']\n",
    "\n",
    "# encode categorical binary features using label encoding\n",
    "for column in label_encoding_columns:\n",
    "    if column == 'gender':\n",
    "        df_telco_transformed[column] = df_telco_transformed[column].map({'Female': 1, 'Male': 0})\n",
    "    else: \n",
    "        df_telco_transformed[column] = df_telco_transformed[column].map({'Yes': 1, 'No': 0}) \n",
    "        \n",
    "# one-hot encoding (categorical variables with more than two levels)\n",
    "one_hot_encoding_columns = ['MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
    "                            'TechSupport', 'StreamingTV',  'StreamingMovies', 'Contract', 'PaymentMethod']\n",
    "\n",
    "# encode categorical variables with more than two levels using one-hot encoding\n",
    "df_telco_transformed = pd.get_dummies(df_telco_transformed, columns = one_hot_encoding_columns)\n",
    "\n",
    "# min-max normalization (numeric variables)\n",
    "min_max_columns = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "# minimum value of the column\n",
    "min_column={} \n",
    "# maximum value of the column\n",
    "max_column={}\n",
    "\n",
    "# scale numerical variables using min max scaler\n",
    "for column in min_max_columns:\n",
    "        # minimum value of the column\n",
    "        min_column[column] = df_telco_transformed[column].min()\n",
    "        # maximum value of the column\n",
    "        max_column[column] = df_telco_transformed[column].max()\n",
    "        # min max scaler\n",
    "        df_telco_transformed[column] = (df_telco_transformed[column] - min_column[column] ) / (max_column[column]  - min_column[column] )   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select independent variables\n",
    "X = df_telco_transformed.drop(columns='Churn')\n",
    "\n",
    "# select dependent variables\n",
    "y = df_telco_transformed.loc[:, 'Churn']\n",
    "\n",
    "\n",
    "# split the data in training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=40, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Assessing multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: dummy_classifier, Accuracy: 0.745164960182025)\n",
      "Classifier: k_nearest_neighbors, Accuracy: 0.7531285551763367)\n",
      "Classifier: support_vector_machines, Accuracy: 0.7878270762229806)\n",
      "Classifier: random_forest, Accuracy: 0.7713310580204779)\n",
      "Classifier: gradient_boosting, Accuracy: 0.7963594994311718)\n"
     ]
    }
   ],
   "source": [
    "def create_models(seed=2):\n",
    "    '''\n",
    "    Create a list of machine learning models.\n",
    "            Parameters:\n",
    "                    seed (integer): random seed of the models\n",
    "            Returns:\n",
    "                    models (list): list containing the models\n",
    "    '''\n",
    "\n",
    "    models = []\n",
    "    models.append(('dummy_classifier', DummyClassifier(random_state=seed, strategy='most_frequent')))\n",
    "    models.append(('k_nearest_neighbors', KNeighborsClassifier()))\n",
    "    #models.append(('logistic_regression', LogisticRegression(random_state=seed)))\n",
    "    models.append(('support_vector_machines', SVC(random_state=seed)))\n",
    "    models.append(('random_forest', RandomForestClassifier(random_state=seed)))\n",
    "    models.append(('gradient_boosting', GradientBoostingClassifier(random_state=seed)))\n",
    "    \n",
    "    return models\n",
    "\n",
    "# create a list with all the algorithms we are going to assess\n",
    "models = create_models()\n",
    "\n",
    "\n",
    "\n",
    "# test the accuracy of each model using default hyperparameters\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    # fit the model with the training data\n",
    "    model.fit(X_train, y_train).predict(X_test)\n",
    "    # make predictions with the testing data\n",
    "    predictions = model.predict(X_test)\n",
    "    # calculate accuracy \n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    # append the model name and the accuracy to the lists\n",
    "    results.append(accuracy)\n",
    "    names.append(name)\n",
    "    # print classifier accuracy\n",
    "    print('Classifier: {}, Accuracy: {})'.format(name, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Let's build our `predict` function \n",
    "\n",
    "we pick here `random_forest`, but feel free to write it with any model of the above.\n",
    "\n",
    "**Important note: notice how we defined `min_column[column]` and `max_column[column]` outside the `predict` function. That's important, as you don't want to `fit` some of your transformers in `predict` even if you write them manually. That's because `predict` takes as input a subset of the full dataset needed to fit some of the transformers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_dataset):\n",
    "    df_telco_transformed=test_dataset.copy()\n",
    "    # label encoding (binary variables)\n",
    "    label_encoding_columns = ['gender', 'Partner', 'Dependents', 'PaperlessBilling', 'PhoneService']\n",
    "\n",
    "    # encode categorical binary features using label encoding\n",
    "    for column in label_encoding_columns:\n",
    "        if column == 'gender':\n",
    "            df_telco_transformed[column] = df_telco_transformed[column].map({'Female': 1, 'Male': 0})\n",
    "        else: \n",
    "            df_telco_transformed[column] = df_telco_transformed[column].map({'Yes': 1, 'No': 0}) \n",
    "\n",
    "    # one-hot encoding (categorical variables with more than two levels)\n",
    "    one_hot_encoding_columns = ['MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
    "                                'TechSupport', 'StreamingTV',  'StreamingMovies', 'Contract', 'PaymentMethod']\n",
    "\n",
    "    # encode categorical variables with more than two levels using one-hot encoding\n",
    "    df_telco_transformed = pd.get_dummies(df_telco_transformed, columns = one_hot_encoding_columns)\n",
    "\n",
    "    # min-max normalization (numeric variables)\n",
    "    min_max_columns = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "    # scale numerical variables using min max scaler\n",
    "    for column in min_max_columns:\n",
    "            # min max scaler\n",
    "            df_telco_transformed[column] = (df_telco_transformed[column] - min_column[column]) / (max_column[column] - min_column[column])   \n",
    "\n",
    "        \n",
    "    # choose model\n",
    "    model = models[3][1] #\n",
    "    \n",
    "    predict\n",
    "    \n",
    "    # make predictions with the testing data\n",
    "    predictions = model.predict_proba(df_telco_transformed)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5'. `predict` function using transformers and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jp/b7681vg128nf8s2hw47sl6380000gn/T/ipykernel_56879/4088596637.py\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Pipeline to fill missing values, transform and scale the numeric columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcolumns_to_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"numeric\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m numeric_transformer = Pipeline([('imputer', SimpleImputer(strategy='median')),\n\u001b[1;32m     12\u001b[0m     ('scaler', StandardScaler())])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_types' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "# Pipeline to fill missing values, transform and scale the numeric columns\n",
    "columns_to_scale = [key for key in feature_types.keys() if feature_types[key]==\"numeric\"]\n",
    "numeric_transformer = Pipeline([('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Pipeline to fill missing values and one hot encode the categorical values\n",
    "columns_to_encode = [key for key in feature_types.keys() if feature_types[key]==\"category\"]\n",
    "categorical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore',sparse=False)) ])\n",
    "\n",
    "# Perform preprocessing of the columns with the above pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, columns_to_scale),\n",
    "      ('cat', categorical_transformer, columns_to_encode)\n",
    "          ]\n",
    ")\n",
    "\n",
    "# choose model\n",
    "model = models[3][1] #\n",
    "\n",
    "# Pipeline for the model Logistic Regression\n",
    "clf_logistic_regression = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', model)])\n",
    "\n",
    "# Split the data into train and test\n",
    "Y=df_telco['Churn']\n",
    "X= df_telco.drop(columns=\"Churn\")\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.20,random_state = 30, stratify = Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf_logistic_regression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jp/b7681vg128nf8s2hw47sl6380000gn/T/ipykernel_56879/16555752.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit the model with the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf_logistic_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# make predictions with the testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_logistic_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# calculate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf_logistic_regression' is not defined"
     ]
    }
   ],
   "source": [
    "# fit the model with the training data\n",
    "clf_logistic_regression.fit(X_train, y_train).predict(X_test)\n",
    "# make predictions with the testing data\n",
    "predictions = clf_logistic_regression.predict(X_test)\n",
    "# calculate accuracy \n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "# append the model name and the accuracy to the lists\n",
    "results.append(accuracy)\n",
    "names.append(name)\n",
    "# print classifier accuracy\n",
    "print('Classifier: {}, Accuracy: {})'.format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# select independent variables\n",
    "X = df_telco.drop(columns='Churn')\n",
    "\n",
    "# select dependent variables\n",
    "y = df_telco.loc[:, 'Churn']\n",
    "\n",
    "\n",
    "# split the data in training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=40, shuffle=True)\n",
    "# Prepare data to upload on Giskard\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Upload the model in Giskard üöÄüöÄüöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "#### Install Giskard library\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: giskard==1.7.0a2 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (1.7.0a2)\n",
      "Requirement already satisfied: numpy<1.22.0,>=1.21.6 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn<1.1.0,>=1.0.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (1.0.2)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (8.1.3)\n",
      "Requirement already satisfied: mixpanel<5.0.0,>=4.9.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (4.10.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.11.1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (4.11.1)\n",
      "Requirement already satisfied: eli5<0.14.0,>=0.13.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (0.13.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (4.64.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.46.3 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (1.48.2)\n",
      "Requirement already satisfied: pydantic<2.0.0,>=1.9.1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (1.9.2)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.46.3 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (1.49.1)\n",
      "Requirement already satisfied: psutil<6.0.0,>=5.9.2 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (5.9.2)\n",
      "Requirement already satisfied: scipy<1.8,>=1.7.2 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (1.7.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (2.28.1)\n",
      "Requirement already satisfied: requests-toolbelt<0.10.0,>=0.9.1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (0.9.1)\n",
      "Requirement already satisfied: lockfile<0.13.0,>=0.12.2 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (0.12.2)\n",
      "Requirement already satisfied: cloudpickle<3.0.0,>=2.1.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (2.2.0)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.9.2 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (3.20.3)\n",
      "Requirement already satisfied: alibi[shap]<0.8.0,>=0.7.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (0.7.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (8.1.0)\n",
      "Requirement already satisfied: importlib_metadata<5.0.0,>=4.11.4 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (4.13.0)\n",
      "Requirement already satisfied: python-daemon<3.0.0,>=2.3.1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (2.3.1)\n",
      "Requirement already satisfied: zstandard<0.16.0,>=0.15.2 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (0.15.2)\n",
      "Requirement already satisfied: setuptools<66.0.0,>=65.4.1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (65.4.1)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.3.5 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from giskard==1.7.0a2) (1.3.5)\n",
      "Requirement already satisfied: dill<0.4.0,>=0.3.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (0.3.5.1)\n",
      "Requirement already satisfied: attrs<22.0.0,>=19.2.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (21.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (4.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.7.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (4.22.2)\n",
      "Requirement already satisfied: scikit-image!=0.17.1,<0.20,>=0.14.2 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (0.19.3)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (3.5.3)\n",
      "Requirement already satisfied: Pillow<10.0,>=5.4.1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (9.2.0)\n",
      "Requirement already satisfied: spacy[lookups]<4.0.0,>=2.0.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (3.4.1)\n",
      "Requirement already satisfied: shap<0.41.0,>=0.40.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (0.40.0)\n",
      "Requirement already satisfied: numba!=0.54.0,<0.56.0,>=0.50.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (0.55.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from beautifulsoup4<5.0.0,>=4.11.1->giskard==1.7.0a2) (2.3.2.post1)\n",
      "Requirement already satisfied: jinja2>=3.0.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from eli5<0.14.0,>=0.13.0->giskard==1.7.0a2) (3.1.2)\n",
      "Requirement already satisfied: graphviz in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from eli5<0.14.0,>=0.13.0->giskard==1.7.0a2) (0.20.1)\n",
      "Requirement already satisfied: six in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from eli5<0.14.0,>=0.13.0->giskard==1.7.0a2) (1.16.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from eli5<0.14.0,>=0.13.0->giskard==1.7.0a2) (0.8.10)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.5.5 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from grpcio-status<2.0.0,>=1.46.3->giskard==1.7.0a2) (1.56.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from importlib_metadata<5.0.0,>=4.11.4->giskard==1.7.0a2) (3.8.1)\n",
      "Requirement already satisfied: urllib3 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from mixpanel<5.0.0,>=4.9.0->giskard==1.7.0a2) (1.26.12)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from pandas<2.0.0,>=1.3.5->giskard==1.7.0a2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from pandas<2.0.0,>=1.3.5->giskard==1.7.0a2) (2022.4)\n",
      "Requirement already satisfied: docutils in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from python-daemon<3.0.0,>=2.3.1->giskard==1.7.0a2) (0.19)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from requests<3.0.0,>=2.28.1->giskard==1.7.0a2) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from requests<3.0.0,>=2.28.1->giskard==1.7.0a2) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from requests<3.0.0,>=2.28.1->giskard==1.7.0a2) (2.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from scikit-learn<1.1.0,>=1.0.0->giskard==1.7.0a2) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from scikit-learn<1.1.0,>=1.0.0->giskard==1.7.0a2) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from jinja2>=3.0.0->eli5<0.14.0,>=0.13.0->giskard==1.7.0a2) (2.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (4.37.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (21.3)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from numba!=0.54.0,<0.56.0,>=0.50.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (0.38.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (2021.11.2)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (2.22.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (2.6.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (1.3.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from shap<0.41.0,>=0.40.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (0.0.7)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (1.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (2.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (2.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (0.6.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (8.1.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (0.4.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (1.0.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (3.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (3.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (2.4.4)\n",
      "Requirement already satisfied: spacy-lookups-data<1.1.0,>=1.0.3 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (1.0.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from transformers<5.0.0,>=4.7.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from transformers<5.0.0,>=4.7.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from transformers<5.0.0,>=4.7.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (0.10.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from transformers<5.0.0,>=4.7.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (2022.9.13)\n",
      "Requirement already satisfied: filelock in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from transformers<5.0.0,>=4.7.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (3.8.0)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from pathy>=0.3.5->spacy[lookups]<4.0.0,>=2.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (5.2.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (0.7.8)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[shap]<0.8.0,>=0.7.0->giskard==1.7.0a2) (0.0.2)\n",
      "2022-10-07 12:53:40,845 pid:56562 giskard.cli  INFO     Starting ML Worker client daemon\n",
      "2022-10-07 12:53:40,846 pid:56562 giskard.cli_utils INFO     Writing logs to /Users/rak/giskard-home/run/ml-worker.log\n"
     ]
    }
   ],
   "source": [
    "!pip install giskard==1.7.0a2\n",
    "!giskard worker start -h 194.163.172.30 -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-07 12:53:41,532 pid:56566 giskard.cli  INFO     Stopped ML Worker Daemon by PID: 56565\r\n"
     ]
    }
   ],
   "source": [
    "!giskard worker stop -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Initiate a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from giskard.client.giskard_client import GiskardClient\n",
    "\n",
    "url = \"http://localhost:9000\" #if Giskard is installed locally (for installation, see: https://docs.giskard.ai/start/guides/installation)\n",
    "#url = \"http://app.giskard.ai\" # If you want to upload on giskard URL\n",
    "token = \"eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJhZG1pbiIsInRva2VuX3R5cGUiOiJBUEkiLCJhdXRoIjoiUk9MRV9BRE1JTiIsImV4cCI6MTY3Mjg0NjAxMX0.oiSJHiLotoyQeFrxv7cf0uGGTpZGIXEWP9kwpTwCxTk\"\n",
    "client = GiskardClient(url, token)\n",
    "\n",
    "# your_project = client.create_project(\"project_key\", \"PROJECT_NAME\", \"DESCRIPTION\")\n",
    "# Choose the arguments you want. But \"project_key\" should be unique and in lower case\n",
    "churn_analysis = client.create_project(\"churn_analysis\", \"Telco Kaggle Churn Analysis\", \"Project to predict if user will default\")\n",
    "\n",
    "# If you've already created a project with the key \"churn-analysis\" use\n",
    "#churn_analysis = client.get_project(\"churn_analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the type of each column in the dataset(example: category, numeric, text)\n",
    "column_types = {'gender': \"category\",\n",
    "                'SeniorCitizen': \"numeric\", \n",
    "                'Partner': \"category\", \n",
    "                'Dependents': \"category\", \n",
    "                'tenure': \"numeric\",\n",
    "                'PhoneService': \"category\", \n",
    "                'MultipleLines': \"category\", \n",
    "                'InternetService': \"category\", \n",
    "                'OnlineSecurity': \"category\",\n",
    "                'OnlineBackup': \"category\", \n",
    "                'DeviceProtection': \"category\", \n",
    "                'TechSupport': \"category\", \n",
    "                'StreamingTV': \"category\",\n",
    "                'StreamingMovies': \"category\", \n",
    "                'Contract': \"category\", \n",
    "                'PaperlessBilling': \"category\", \n",
    "                'PaymentMethod': \"category\",\n",
    "                'MonthlyCharges': \"numeric\", \n",
    "                'TotalCharges': \"numeric\", \n",
    "                'Churn': \"category\"}\n",
    "\n",
    "# feature_types is used to declare the features the model is trained on\n",
    "feature_types = {i:column_types[i] for i in column_types if i!='Churn'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rak/Documents/giskard-client/.venv/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 40 features, but RandomForestClassifier is expecting 45 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jp/b7681vg128nf8s2hw47sl6380000gn/T/ipykernel_56555/1667275132.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/jp/b7681vg128nf8s2hw47sl6380000gn/T/ipykernel_56555/3271424210.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(test_dataset)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# make predictions with the testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_telco_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/giskard-client/.venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/giskard-client/.venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    577\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    578\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/giskard-client/.venv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/giskard-client/.venv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 40 features, but RandomForestClassifier is expecting 45 features as input."
     ]
    }
   ],
   "source": [
    "predict(test_data[list(feature_types.keys())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Upload your model and a dataset (see [documentation](https://docs.giskard.ai/start/guides/upload-your-model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully uploaded to project key 'churn_analysis' and is available at http://localhost:9000 \n",
      "Model successfully uploaded to project key 'churn_analysis' and is available at http://localhost:9000 \n"
     ]
    }
   ],
   "source": [
    "churn_analysis.upload_model_and_df(\n",
    "    prediction_function=clf_logistic_regression.predict_proba, # Python function which takes pandas dataframe as input and returns probabilities for classification model OR returns predictions for regression model\n",
    "    model_type='classification', # \"classification\" for classification model OR \"regression\" for regression model\n",
    "    df=test_data, # the dataset you want to use to inspect your model\n",
    "    column_types=column_types, # A dictionary with columns names of df as key and types(category, numeric, text) of columns as values\n",
    "    target='Churn', # The column name in df corresponding to the actual target variable (ground truth).\n",
    "    feature_names=list(feature_types.keys()), # List of the feature names of prediction_function\n",
    "    classification_labels=[\"Yes\",\"No\"] ,  # List of the classification labels of your prediction #TODO: Check their order!!!!!\n",
    "    model_name='random_forest', # Name of the model\n",
    "    dataset_name='test_data' # Name of the dataset\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "German_credit_scoring_giskard (2).ipynb",
   "provenance": []
  },
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_app_layout": "article",
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "6e7ea85d-f19e-4d05-90a4-44b7668fd037",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
