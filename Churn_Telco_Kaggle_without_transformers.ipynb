{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pvKxJjsNSoE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![giskard_logo.png](https://raw.githubusercontent.com/Giskard-AI/giskard/main/readme/Logo_full_darkgreen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a9b17467105f4031a3f9eae70ef4138f",
    "deepnote_cell_height": 134,
    "deepnote_cell_type": "markdown",
    "id": "PKcOi3D37xbW",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# About Giskard\n",
    "\n",
    "Open-Source CI/CD platform for ML teams. Deliver ML products, better & faster. \n",
    "\n",
    "*   Collaborate faster with feedback from business stakeholders.\n",
    "*   Deploy automated tests to eliminate regressions, errors & biases.\n",
    "\n",
    "üè° [Website](https://giskard.ai/)\n",
    "\n",
    "üìó [Documentation](https://docs.giskard.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f35c8e8d3fbf4c0f9c01a69673c318a1",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 6
    },
    "deepnote_cell_height": 110,
    "deepnote_cell_type": "markdown",
    "id": "mJTqM-W_7xbW",
    "owner_user_id": "41ec0844-b5b7-49c2-9460-710a452f98de",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Telco custormer churn data\n",
    "\n",
    "In this notebook we explore how to predict customer churn, a critical factor for telecommunication companies to be able to effectively retain customers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing `giskard` and `lightgbm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install giskard lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e8d609f32d5243dd917cc3104599b8d8",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 12
    },
    "deepnote_cell_height": 230,
    "deepnote_cell_type": "markdown",
    "id": "WNI85koE7xbX",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## 1. Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import lightgbm as lbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import telecom dataset into a pandas data frame\n",
    "\n",
    "dataset_url=\"https://raw.githubusercontent.com/Giskard-AI/examples/main/datasets/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
    "\n",
    "df_telco=pd.read_csv(dataset_url)\n",
    "\n",
    "# check unique values of each column\n",
    "#for column in df_telco.columns:\n",
    "#    print('Column: {} - Unique Values: {}'.format(column, df_telco[column].unique()))\n",
    "\n",
    "# summary of the data frame\n",
    "#df_telco.info()\n",
    "\n",
    "# transform the column TotalCharges into a numeric data type\n",
    "df_telco['TotalCharges'] = pd.to_numeric(df_telco['TotalCharges'], errors='coerce')\n",
    "\n",
    "# drop observations with null values\n",
    "df_telco.dropna(inplace=True)\n",
    "\n",
    "# drop the customerID column from the dataset\n",
    "df_telco.drop(columns='customerID', inplace=True)\n",
    "\n",
    "# remove (automatic) from payment method names\n",
    "df_telco['PaymentMethod'] = df_telco['PaymentMethod'].str.replace(' (automatic)', '', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialising feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the type of each column in the dataset(example: category, numeric, text)\n",
    "column_types = {'gender': \"category\",\n",
    "                'SeniorCitizen': \"numeric\", \n",
    "                'Partner': \"category\", \n",
    "                'Dependents': \"category\", \n",
    "                'tenure': \"numeric\",\n",
    "                'PhoneService': \"category\", \n",
    "                'MultipleLines': \"category\", \n",
    "                'InternetService': \"category\", \n",
    "                'OnlineSecurity': \"category\",\n",
    "                'OnlineBackup': \"category\", \n",
    "                'DeviceProtection': \"category\", \n",
    "                'TechSupport': \"category\", \n",
    "                'StreamingTV': \"category\",\n",
    "                'StreamingMovies': \"category\", \n",
    "                'Contract': \"category\", \n",
    "                'PaperlessBilling': \"category\", \n",
    "                'PaymentMethod': \"category\",\n",
    "                'MonthlyCharges': \"numeric\", \n",
    "                'TotalCharges': \"numeric\", \n",
    "                'Churn': \"category\"}\n",
    "\n",
    "# feature_types is used to declare the features the model is trained on\n",
    "feature_types = {i:column_types[i] for i in column_types if i!='Churn'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering (manual, without sklearn transformers)\n",
    "\n",
    "In this notebook, we're going to wrap some of these transformations (except one-hot encoding) inside a `predict` function instead of redefining the transformations in terms of sklearn pre-defined ones. \n",
    "\n",
    "**Important note: All the transformers, need to be fitted outside the `prediction_function` passed to Giskard, to ensure similar transformations throughout the code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_telco_transformed = df_telco.copy()\n",
    "\n",
    "# label encoding (binary variables)\n",
    "label_encoding_columns = ['gender', 'Partner', 'Dependents', 'PaperlessBilling', 'PhoneService', 'Churn']\n",
    "\n",
    "# encode categorical binary features using label encoding\n",
    "for column in label_encoding_columns:\n",
    "    if column == 'gender':\n",
    "        df_telco_transformed[column] = df_telco_transformed[column].map({'Female': 1, 'Male': 0})\n",
    "    else: \n",
    "        df_telco_transformed[column] = df_telco_transformed[column].map({'Yes': 1, 'No': 0}) \n",
    "        \n",
    "# one-hot encoding (categorical variables with more than two levels)\n",
    "one_hot_encoding_columns = ['MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
    "                            'TechSupport', 'StreamingTV',  'StreamingMovies', 'Contract', 'PaymentMethod']\n",
    "\n",
    "#Use OneHotEncoder / optional: use drop='first' for OneHotEncoder to eliminate duplicate features\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "array_hot_encoded =  one_hot_encoder.fit_transform(df_telco_transformed[one_hot_encoding_columns])\n",
    "data_hot_encoded = pd.DataFrame(array_hot_encoded, index=df_telco_transformed.index,columns=one_hot_encoder.get_feature_names_out())\n",
    "df_telco_transformed=df_telco_transformed.drop(columns=one_hot_encoding_columns)\n",
    "df_telco_transformed = pd.concat([df_telco_transformed,data_hot_encoded], axis=1)\n",
    "\n",
    "# encode categorical variables with more than two levels using one-hot encoding\n",
    "# df_telco_transformed = pd.get_dummies(df_telco_transformed, columns = one_hot_encoding_columns)\n",
    "\n",
    "# min-max normalization (numeric variables)\n",
    "min_max_columns = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "# minimum value of the column\n",
    "min_column={} \n",
    "# maximum value of the column\n",
    "max_column={}\n",
    "\n",
    "# scale numerical variables using min max scaler\n",
    "for column in min_max_columns:\n",
    "        # minimum value of the column\n",
    "        min_column[column] = df_telco_transformed[column].min()\n",
    "        # maximum value of the column\n",
    "        max_column[column] = df_telco_transformed[column].max()\n",
    "        # min max scaler\n",
    "        df_telco_transformed[column] = (df_telco_transformed[column] - min_column[column] ) / (max_column[column]  - min_column[column] )   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ raw data\n",
    "# select independent variables\n",
    "X_raw = df_telco.drop(columns='Churn')\n",
    "\n",
    "# select dependent variables\n",
    "Y_raw = df_telco.loc[:, 'Churn']\n",
    "\n",
    "# split the data in training and testing sets\n",
    "X_raw_train, X_raw_test, Y_raw_train, Y_raw_test = train_test_split(X_raw, Y_raw, test_size=0.25, random_state=40, shuffle=True)\n",
    "# Prepare data to upload on Giskard\n",
    "train_raw_data = pd.concat([X_raw_train, Y_raw_train], axis=1)\n",
    "test_raw_data = pd.concat([X_raw_test, Y_raw_test ], axis=1)\n",
    "\n",
    "#------ transformed data\n",
    "# select independent variables\n",
    "X = df_telco_transformed.drop(columns='Churn')\n",
    "\n",
    "# select dependent variables\n",
    "Y = df_telco_transformed.loc[:, 'Churn']\n",
    "\n",
    "# split the data in training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=40, shuffle=True)\n",
    "# Prepare data to upload on Giskard\n",
    "train_data = pd.concat([X_train, Y_train], axis=1)\n",
    "test_data = pd.concat([X_test, Y_test ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=123\n",
    "models = {}\n",
    "models['dummy_classifier']= {\"model\": DummyClassifier(random_state=seed, strategy='most_frequent'), \"accuracy\":0} \n",
    "models['k_nearest_neighbors']= {\"model\": KNeighborsClassifier(), \"accuracy\":0} \n",
    "models['logistic_regression']= {\"model\": LogisticRegression(random_state=seed), \"accuracy\":0} \n",
    "models['random_forest']= {\"model\": RandomForestClassifier(random_state=seed), \"accuracy\":0} \n",
    "models['gradient_boosting']= {\"model\": GradientBoostingClassifier(random_state=seed), \"accuracy\":0} \n",
    "models['LGBM']= {\"model\": lbt.LGBMClassifier(random_state=seed), \"accuracy\":0} \n",
    "    \n",
    "\n",
    "# test the accuracy of each model using default hyperparameters\n",
    "scoring = 'accuracy'\n",
    "for name in models.keys():\n",
    "    # fit the model with the training data\n",
    "    models[name]['model'].fit(X_train, Y_train).predict(X_test)\n",
    "    # make predictions with the testing data\n",
    "    predictions = models[name]['model'].predict(X_test)\n",
    "    # calculate accuracy \n",
    "    accuracy = accuracy_score(Y_test, predictions)\n",
    "    # append the model name and the accuracy to the lists\n",
    "    models[name]['accuracy']=accuracy\n",
    "    # print classifier accuracy\n",
    "    print('Classifier: {}, Accuracy: {})'.format(name, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Let's build our `wrapped_prediction_function` function \n",
    "\n",
    "we pick here `LGBM`, but feel free to write it with any model of the above.\n",
    "\n",
    "**Important note: notice how we defined `min_column[column]` and `max_column[column]` outside the `wrapped_prediction_function` function. That's important, as you don't want to `fit` some of your transformers in `wrapped_prediction_function` even if you write them manually. That's because `wrapped_prediction_function` takes as input a subset of the full dataset needed to fit some of the transformers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapped_prediction_function(test_dataset):\n",
    "    df_telco_transformed=test_dataset.copy()\n",
    "    # label encoding (binary variables)\n",
    "    label_encoding_columns = ['gender', 'Partner', 'Dependents', 'PaperlessBilling', 'PhoneService']\n",
    "\n",
    "    # encode categorical binary features using label encoding\n",
    "    for column in label_encoding_columns:\n",
    "        if column == 'gender':\n",
    "            df_telco_transformed[column] = df_telco_transformed[column].map({'Female': 1, 'Male': 0})\n",
    "        else: \n",
    "            df_telco_transformed[column] = df_telco_transformed[column].map({'Yes': 1, 'No': 0}) \n",
    "\n",
    "    # one-hot encoding (categorical variables with more than two levels)\n",
    "    array_hot_encoded =  one_hot_encoder.transform(df_telco_transformed[one_hot_encoding_columns])\n",
    "    data_hot_encoded = pd.DataFrame(array_hot_encoded, index=df_telco_transformed.index,columns=one_hot_encoder.get_feature_names_out())\n",
    "    df_telco_transformed=df_telco_transformed.drop(columns=one_hot_encoding_columns)\n",
    "    df_telco_transformed = pd.concat([df_telco_transformed,data_hot_encoded], axis=1)\n",
    "\n",
    "    # min-max normalization (numeric variables)\n",
    "    min_max_columns = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "    # scale numerical variables using min max scaler\n",
    "    for column in min_max_columns:\n",
    "            # min max scaler\n",
    "            df_telco_transformed[column] = (df_telco_transformed[column] - min_column[column]) / (max_column[column] - min_column[column])   \n",
    "\n",
    "        \n",
    "    # choose model\n",
    "    model = models['LGBM']['model']\n",
    "    \n",
    "    # make predictions with the testing data\n",
    "    predictions = model.predict_proba(df_telco_transformed)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Upload the model in Giskard üöÄüöÄüöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initiate a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from giskard.client.giskard_client import GiskardClient\n",
    "\n",
    "url = \"http://localhost:19000\" #if Giskard is installed locally (for installation, see: https://docs.giskard.ai/start/guides/installation)\n",
    "#url = \"http://app.giskard.ai\" # If you want to upload on giskard URL\n",
    "token = \"YOUR GENERATED TOKEN\"\n",
    "client = GiskardClient(url, token)\n",
    "\n",
    "# your_project = client.create_project(\"project_key\", \"PROJECT_NAME\", \"DESCRIPTION\")\n",
    "# Choose the arguments you want. But \"project_key\" should be unique and in lower case\n",
    "churn_analysis_wo_tfs = client.create_project(\"churn_analysis_without_transformers\", \"Telco Kaggle Churn Analysis\", \"Project to predict if a customer quits\")\n",
    "\n",
    "# If you've already created a project with the key \"churn-analysis\" use\n",
    "#churn_analysis = client.get_project(\"churn_analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the type of each column in the dataset(example: category, numeric, text)\n",
    "column_types = {'gender': \"category\",\n",
    "                'SeniorCitizen': \"category\", \n",
    "                'Partner': \"category\", \n",
    "                'Dependents': \"category\", \n",
    "                'tenure': \"numeric\",\n",
    "                'PhoneService': \"category\", \n",
    "                'MultipleLines': \"category\", \n",
    "                'InternetService': \"category\", \n",
    "                'OnlineSecurity': \"category\",\n",
    "                'OnlineBackup': \"category\", \n",
    "                'DeviceProtection': \"category\", \n",
    "                'TechSupport': \"category\", \n",
    "                'StreamingTV': \"category\",\n",
    "                'StreamingMovies': \"category\", \n",
    "                'Contract': \"category\", \n",
    "                'PaperlessBilling': \"category\", \n",
    "                'PaymentMethod': \"category\",\n",
    "                'MonthlyCharges': \"numeric\", \n",
    "                'TotalCharges': \"numeric\", \n",
    "                'Churn': \"category\"}\n",
    "\n",
    "# feature_types is used to declare the features the model is trained on\n",
    "feature_types = {i:column_types[i] for i in column_types if i!='Churn'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Upload your model and a dataset (see [documentation](https://docs.giskard.ai/start/guides/upload-your-model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "churn_analysis_wo_tfs.upload_model_and_df(\n",
    "    prediction_function=wrapped_prediction_function, # Python function which takes pandas dataframe as input and returns probabilities for classification model OR returns predictions for regression model\n",
    "    model_type='classification', # \"classification\" for classification model OR \"regression\" for regression model\n",
    "    df=test_raw_data, # the dataset you want to use to inspect your model\n",
    "    column_types=column_types, # A dictionary with columns names of df as key and types(category, numeric, text) of columns as values\n",
    "    target='Churn', # The column name in df corresponding to the actual target variable (ground truth).\n",
    "    feature_names=list(feature_types.keys()), # List of the feature names of prediction_function\n",
    "    classification_labels=[\"No\",\"Yes\"] ,  # List of the classification labels of your prediction #TODO: Check their order!!!!!\n",
    "    model_name='LGBM', # Name of the model\n",
    "    dataset_name='test_data' # Name of the dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload more datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_analysis_wo_tfs.upload_df(\n",
    "    df=train_raw_data, # The dataset you want to upload\n",
    "    column_types=column_types, # All the column types of df\n",
    "    target=\"Churn\", # Do not pass this parameter if dataset doesn't contain target column\n",
    "    name=\"train_data\" # Name of the dataset\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "German_credit_scoring_giskard (2).ipynb",
   "provenance": []
  },
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_app_layout": "article",
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "6e7ea85d-f19e-4d05-90a4-44b7668fd037",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
