{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Amazon reviews classification [sklearn]\n",
    "Binary classification of product's review 'helpfulness' (quality).\n",
    "Reference: <https://t-lanigan.github.io/amazon-review-classifier/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:30:50.252989Z",
     "end_time": "2023-05-03T14:30:53.017784Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install nltk giskard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:30:53.023731Z",
     "end_time": "2023-05-03T14:30:57.627957Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import giskard\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from giskard import GiskardClient\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from giskard import wrap_dataset, wrap_model\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook-level settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:30:57.629373Z",
     "end_time": "2023-05-03T14:30:57.634591Z"
    }
   },
   "outputs": [],
   "source": [
    "# Disable chained assignment warning.\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:30:57.638199Z",
     "end_time": "2023-05-03T14:30:57.645649Z"
    }
   },
   "outputs": [],
   "source": [
    "# Constants.\n",
    "RANDOM_SEED = 0\n",
    "TEST_RATIO = 0.2\n",
    "\n",
    "TARGET_THRESHOLD = 0.5\n",
    "TARGET_NAME = \"isHelpful\"\n",
    "\n",
    "# Paths.\n",
    "DATASET_URL = 'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Apps_for_Android_5.json.gz'\n",
    "\n",
    "# Giskard platform credentials.\n",
    "GISKARD_URL = \"http://localhost:19000\"\n",
    "GISKARD_ACCESS_TOKEN = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:30:57.648107Z",
     "end_time": "2023-05-03T14:30:57.676672Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_data(**kwargs: dict) -> pd.DataFrame:\n",
    "    \"\"\"Download the dataset using URL.\"\"\"\n",
    "    print(f\"Downloading dataset from {DATASET_URL}\")\n",
    "\n",
    "    _df = pd.read_json(DATASET_URL, compression=\"gzip\", lines=True, **kwargs)\n",
    "\n",
    "    print(f\"Dataset was loaded!\")\n",
    "\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:30:57.661027Z",
     "end_time": "2023-05-03T14:30:57.676952Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Perform data-preprocessing steps.\"\"\"\n",
    "    print(f\"Start data preprocessing...\")\n",
    "\n",
    "    # Select columns.\n",
    "    _df = _df[[\"reviewText\", \"helpful\"]]\n",
    "\n",
    "    # Remove Null-characters (x00) from the dataset.\n",
    "    _df.reviewText = _df.reviewText.apply(lambda x: x.replace(\"\\x00\", \"\"))\n",
    "\n",
    "    # Extract numbers of helpful and total votes.\n",
    "    _df['helpful_ratings'] = _df.helpful.apply(lambda x: x[0])\n",
    "    _df['total_ratings'] = _df.helpful.apply(lambda x: x[1])\n",
    "\n",
    "    # Filter unreasonable comments.\n",
    "    _df = _df[_df.total_ratings > 10]\n",
    "\n",
    "    # Create target column.\n",
    "    _df[TARGET_NAME] = np.where((_df.helpful_ratings / _df.total_ratings) > TARGET_THRESHOLD, 1, 0).astype(int)\n",
    "\n",
    "    # Delete columns we don't need anymore.\n",
    "    _df.drop(columns=[\"helpful\", 'helpful_ratings', 'total_ratings'], inplace=True)\n",
    "\n",
    "    print(\"Data preprocessing finished!\")\n",
    "\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:30:57.678899Z",
     "end_time": "2023-05-03T14:31:36.050410Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews_df = download_data()\n",
    "reviews_df = preprocess_data(reviews_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:31:36.069523Z",
     "end_time": "2023-05-03T14:31:36.107100Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews_df[[\"reviewText\"]], reviews_df[TARGET_NAME],\n",
    "                                                    test_size=TEST_RATIO, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:31:36.126839Z",
     "end_time": "2023-05-03T14:31:36.163994Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = pd.concat([X_test, y_test], axis=1)\n",
    "wrapped_dataset = wrap_dataset(test_dataset,\n",
    "                               name=\"reviews\", target=TARGET_NAME, column_types={\"reviewText\": \"text\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:31:36.170619Z",
     "end_time": "2023-05-03T14:31:36.208959Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_lowercase(x):\n",
    "    \"\"\"Lower an input string.\"\"\"\n",
    "    x = x.reviewText.apply(lambda row: row.lower())\n",
    "    return x\n",
    "\n",
    "def remove_punctuation(x):\n",
    "    \"\"\"Remove punctuation from input string.\"\"\"\n",
    "    x.apply(lambda row: row.translate(str.maketrans('', '', string.punctuation)))\n",
    "    return x\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def tokenizer(x):\n",
    "    \"\"\"Define string tokenization logic.\"\"\"\n",
    "    x = x.split()\n",
    "    stems = list()\n",
    "    [stems.append(stemmer.stem(word)) for word in x]\n",
    "    return stems\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenizer, stop_words='english', ngram_range=(1, 1), min_df=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:31:36.181987Z",
     "end_time": "2023-05-03T14:31:36.258532Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = Pipeline(steps=[\n",
    "    (\"lowercase\", FunctionTransformer(make_lowercase)),\n",
    "    (\"punctuation\", FunctionTransformer(remove_punctuation)),\n",
    "    (\"vectorizer\", vectorizer)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:31:36.194027Z",
     "end_time": "2023-05-03T14:31:36.264227Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimator\", LogisticRegression(random_state=RANDOM_SEED))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:31:36.234864Z",
     "end_time": "2023-05-03T14:32:02.651934Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:32:02.676538Z",
     "end_time": "2023-05-03T14:32:34.099385Z"
    }
   },
   "outputs": [],
   "source": [
    "train_metric = roc_auc_score(y_train, pipeline.predict_proba(X_train)[:, 1].T)\n",
    "test_metric = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1].T)\n",
    "\n",
    "print(f\"Train ROC-AUC score: {train_metric}\")\n",
    "print(f\"Test ROC-AUC score: {test_metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:32:34.103944Z",
     "end_time": "2023-05-03T14:32:34.110527Z"
    }
   },
   "outputs": [],
   "source": [
    "wrapped_model = wrap_model(model=pipeline,\n",
    "                           model_type=\"classification\",\n",
    "                           feature_names=[\"reviewText\"],\n",
    "                           name=\"review_helpfulness_predictor\",\n",
    "                           classification_threshold=0.5,\n",
    "                           classification_labels=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:32:34.113819Z",
     "end_time": "2023-05-03T14:33:15.231801Z"
    }
   },
   "outputs": [],
   "source": [
    "results = giskard.scan(model=wrapped_model, dataset=wrapped_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:33:15.242701Z",
     "end_time": "2023-05-03T14:33:15.350806Z"
    }
   },
   "outputs": [],
   "source": [
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload model and dataset to the Giskard platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:33:15.357245Z",
     "end_time": "2023-05-03T14:33:29.314708Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define project key.\n",
    "project_key = \"amazon_review_classification\"\n",
    "\n",
    "# Init new giskard client.\n",
    "client = GiskardClient(GISKARD_URL, GISKARD_ACCESS_TOKEN)\n",
    "\n",
    "# Create new project.\n",
    "# project = client.create_project(project_key, \"AMAZON_REVIEW_CLASSIFICATION\", \"Amazon product review's binary classification task.\")\n",
    "\n",
    "# Or get the one already created.\n",
    "project = client.get_project(project_key)\n",
    "\n",
    "# Upload the model and the dataset.\n",
    "model_id = wrapped_model.upload(client, project_key)\n",
    "dataset_id = wrapped_dataset.upload(client, project_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
