{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eup4gpgVoA10"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from giskard import Model, Dataset, GiskardClient, scan, testing"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "TARGET_MAP = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tech\"}\n",
    "TARGET_COLUMN_NAME = \"label\"\n",
    "FEATURE_COLUMN_NAME = \"text\"\n",
    "\n",
    "LOADERS_BATCH_SIZE = 64"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data, test_data = AG_NEWS()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wrap dataset with Giskard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_data = pd.DataFrame({FEATURE_COLUMN_NAME: text, TARGET_COLUMN_NAME: TARGET_MAP[label_id]} for label_id, text in test_data)\n",
    "wrapped_data = Dataset(raw_data, name=\"Test Dataset\", target=\"label\", feature_types={FEATURE_COLUMN_NAME: \"text\", TARGET_COLUMN_NAME: \"category\"})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare dataloaders for training and evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple English tokenizer provided by torchtext.\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "# Build a vocabulary from all the tokens we can find in the train data.\n",
    "vocab = build_vocab_from_iterator((tokenizer(text) for _, text in train_data), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "\n",
    "def preprocess_text(raw_text):\n",
    "    return vocab(tokenizer(raw_text))\n",
    "\n",
    "\n",
    "def preprocess_label(raw_label):\n",
    "    return int(raw_label) - 1\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(preprocess_label(_label))\n",
    "        processed_text = torch.tensor(preprocess_text(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "\n",
    "    return label_list.to(DEVICE), text_list.to(DEVICE), offsets.to(DEVICE)\n",
    "\n",
    "\n",
    "# Create the datasets\n",
    "train_dataset = to_map_style_dataset(train_data)\n",
    "test_dataset = to_map_style_dataset(test_data)\n",
    "\n",
    "# We further divide the training data into a train and validation split.\n",
    "train_split, valid_split = random_split(train_dataset, [0.95, 0.05])\n",
    "\n",
    "# Prepare the data loaders\n",
    "train_dataloader = DataLoader(train_split, batch_size=LOADERS_BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dataloader = DataLoader(valid_split, batch_size=LOADERS_BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=LOADERS_BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zgbK39d6oA14"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_range = 0.5\n",
    "        self.embedding.weight.data.uniform_(-init_range, init_range)\n",
    "        self.fc.weight.data.uniform_(-init_range, init_range)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded).softmax(axis=-1)\n",
    "\n",
    "model = TextClassificationModel(vocab_size=vocab, embed_dim=64, num_class=4).to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train and evaluate model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tnYAEF9OoA14"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.1)\n",
    "\n",
    "\n",
    "def train_epoch(dataloader):\n",
    "    model.train()\n",
    "\n",
    "    train_accuracy = total_count = 0\n",
    "    for label, text, offset in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offset)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        train_accuracy += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "\n",
    "    return train_accuracy / total_count\n",
    "\n",
    "\n",
    "def validation_epoch(dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    validation_accuracy = total_count = 0\n",
    "    with torch.no_grad():\n",
    "        for label, text, offsets in dataloader:\n",
    "            predicted_label = model(text, offsets)\n",
    "            validation_accuracy += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "\n",
    "    return validation_accuracy / total_count\n",
    "\n",
    "\n",
    "total_accuracy = None\n",
    "for epoch in range(1, 11):\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    train_epoch(train_dataloader)\n",
    "    accu_val = validation_epoch(valid_dataloader)\n",
    "\n",
    "    if total_accuracy is not None and total_accuracy > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accuracy = accu_val\n",
    "\n",
    "    print(\"-\" * 59)\n",
    "    print(f\"| end of epoch {epoch: .3f} | time: {time.perf_counter() - start_time :5.2f}s | valid accuracy {accu_val:8.3f} \")\n",
    "    print(\"-\" * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uy9ziVhloA15"
   },
   "outputs": [],
   "source": [
    "test_accuracy = validation_epoch(test_dataloader)\n",
    "print('Test accuracy {:8.3f}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Infer predictions on the example data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OqLsJeQGoA15"
   },
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(preprocess_text(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example_news = (\n",
    "    \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \"\n",
    "    \"enduring the season’s worst weather conditions on Sunday at The \"\n",
    "    \"Open on his way to a closing 75 at Royal Portrush, which \"\n",
    "    \"considering the wind and the rain was a respectable showing. \"\n",
    "    \"Thursday’s first round at the WGC-FedEx St. Jude Invitational \"\n",
    "    \"was another story. With temperatures in the mid-80s and hardly any \"\n",
    "    \"wind, the Spaniard was 13 strokes better in a flawless round. \"\n",
    "    \"Thanks to his best putting performance on the PGA Tour, Rahm \"\n",
    "    \"finished with an 8-under 62 for a three-stroke lead, which \"\n",
    "    \"was even more impressive considering he’d never played the \"\n",
    "    \"front nine at TPC Southwind.\"\n",
    ")\n",
    "\n",
    "predicted = predict(example_news)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wrap model with Giskard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prediction_function(df) -> np.ndarray:\n",
    "    predictions = predict(df.text)\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "    return predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OnQKNsE8zmA4"
   },
   "outputs": [],
   "source": [
    "wrapped_model = Model(model,\n",
    "                      name=\"SimpleNewsClassificationModel\",\n",
    "                      feature_names=[\"text\"],\n",
    "                      model_type=\"classification\",\n",
    "                      classification_labels=list(TARGET_MAP.values()))\n",
    "\n",
    "# Validate wrapped model.\n",
    "wrapped_model.predict(wrapped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scan model with Giskard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = scan(wrapped_model, wrapped_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate a test suite from the Scan\n",
    "The objects produced by the scan can be used as fixtures to generate a test suite that integrate domain-specific issues. To create custom tests, refer to the Test your ML Model page."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_suite = results.generate_test_suite(\"My first test suite\")\n",
    "test_suite.run()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Customize your suite by loading objects from the Giskard catalog\n",
    "\n",
    "The Giskard open source catalog will enable to load:\n",
    "* Tests such as metamorphic, performance, prediction & data drift, statistical tests, etc\n",
    "* Slicing functions such as detectors of toxicity, hate, emotion, etc\n",
    "* Transformation functions such as generators of typos, paraphrase, style tune, etc\n",
    "\n",
    "For demo purposes, we will load a simple unit test (test_f1) that checks if the test F1 score is above the given threshold. For more examples of tests and functions, refer to the Giskard catalog."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_suite.add_test(testing.test_f1(model=wrapped_model, dataset=wrapped_data, threshold=0.7)).run()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Upload your suite to the Giskard server\n",
    "\n",
    "Upload your suite to the Giskard server to:\n",
    "* Compare models to decide which model to promote\n",
    "* Debug your tests to diagnose the issues\n",
    "* Create more domain-specific tests that are integrating business feedback\n",
    "* Share your results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Uploading the test suite will automatically save the model, dataset, tests, slicing & transformation functions inside the Giskard UI server\n",
    "# Create a Giskard client after having install the Giskard server (see documentation)\n",
    "token = \"API_TOKEN\"  # Find it in Settings in the Giskard server\n",
    "\n",
    "client = GiskardClient(\n",
    "    url=\"http://localhost:19000\",  # URL of your Giskard instance\n",
    "    token=token\n",
    ")\n",
    "\n",
    "my_project = client.create_project(\"my_project\", \"PROJECT_NAME\", \"DESCRIPTION\")\n",
    "\n",
    "# Upload to the current project ✉️\n",
    "test_suite.upload(client, \"my_project\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
