{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XA0apbYgxWgg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers.integrations import MLflowCallback, TensorBoardCallback\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "from giskard import Dataset, Model, scan, testing, GiskardClient"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATA_URL = 'https://raw.githubusercontent.com/Giskard-AI/examples/main/datasets/twitter_us_airline_sentiment_analysis.csv'\n",
    "\n",
    "MODEL_NAME = \"Souvikcmsa/SentimentAnalysisDistillBERT\"\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "\n",
    "FEATURE_COLUMN_NAME = \"text\"\n",
    "TARGET_COLUMN_NAME = \"airline_sentiment\"\n",
    "\n",
    "TARGET_MAPPING = {'negative': 0, 'neutral': 1, 'positive': 2}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Read data.\n",
    "    df = pd.read_csv(DATA_URL, usecols=[FEATURE_COLUMN_NAME, TARGET_COLUMN_NAME])\n",
    "\n",
    "    # Encode target.\n",
    "    df[TARGET_COLUMN_NAME] = df[TARGET_COLUMN_NAME].map(TARGET_MAPPING)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = load_data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train-test split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[[FEATURE_COLUMN_NAME]], data[TARGET_COLUMN_NAME], random_state=RANDOM_SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wrap dataset with Giskard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wrapped_data = Dataset(df=pd.concat([X_test, y_test], axis=1),\n",
    "                       name=\"Tweets sentiment dataset\",\n",
    "                       target=TARGET_COLUMN_NAME,\n",
    "                       column_types={FEATURE_COLUMN_NAME: \"text\"})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define 'torch.Dataset' objects."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CustomDataset(TorchDataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define tokenizer.\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "X_train_tokenized = tokenizer(list(X_train.text), padding=True, truncation=True, max_length=256)\n",
    "X_test_tokenized = tokenizer(list(X_test.text), padding=True, truncation=True, max_length=256)\n",
    "\n",
    "train_dataset = CustomDataset(X_train_tokenized, y_train.values.tolist())\n",
    "val_dataset = CustomDataset(X_test_tokenized, y_test.values.tolist())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define model to train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5oseyfAwQTdr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(MODEL_NAME).train()\n",
    "\n",
    "# Freeze 'DistillBert' feature extraction module.\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define trainer object"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eO67ZdIBekE5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    probs, y_true = eval_pred\n",
    "    y_pred = np.argmax(probs, axis=1)\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return {\"f1\": f1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    optim=\"adamw_torch\",\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"no\",\n",
    "    disable_tqdm=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    # args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.remove_callback(MLflowCallback)\n",
    "trainer.remove_callback(TensorBoardCallback)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train and evaluate model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8sbXBdhS9ur",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Wrap model with Giskard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Xa0R90auV0w",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prediction_function(df) -> np.ndarray:\n",
    "    input_text = list(df[FEATURE_COLUMN_NAME])\n",
    "    text_tokenized = tokenizer(input_text, padding=True, truncation=True, max_length=256)\n",
    "\n",
    "    # Make prediction.\n",
    "    raw_pred = model.forward(input_ids=torch.tensor(text_tokenized[\"input_ids\"]), attention_mask=torch.tensor(X_test_tokenized[\"attention_mask\"]))\n",
    "    predictions = torch.nn.functional.softmax(raw_pred[\"logits\"], dim=-1)\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "\n",
    "    return predictions\n",
    "\n",
    "wrapped_model = Model(prediction_function,\n",
    "                      model_type=\"classification\",\n",
    "                      name=\"Twitter sentiment classifier\",\n",
    "                      feature_names=[FEATURE_COLUMN_NAME],\n",
    "                      classification_labels=TARGET_MAPPING.values())\n",
    "\n",
    "print(f\"Wrapped Test F1-Score: {f1_score(y_test, wrapped_model.predict(wrapped_data).raw_prediction, average='macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFvZwm4yTjkg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Scan model with Giskard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = scan(wrapped_model, wrapped_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate a test suite from the Scan\n",
    "The objects produced by the scan can be used as fixtures to generate a test suite that integrate domain-specific issues. To create custom tests, refer to the Test your ML Model page."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_suite = results.generate_test_suite(\"My first test suite\")\n",
    "test_suite.run()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Customize your suite by loading objects from the Giskard catalog\n",
    "\n",
    "The Giskard open source catalog will enable to load:\n",
    "* Tests such as metamorphic, performance, prediction & data drift, statistical tests, etc\n",
    "* Slicing functions such as detectors of toxicity, hate, emotion, etc\n",
    "* Transformation functions such as generators of typos, paraphrase, style tune, etc\n",
    "\n",
    "For demo purposes, we will load a simple unit test (test_f1) that checks if the test F1 score is above the given threshold. For more examples of tests and functions, refer to the Giskard catalog."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_suite.add_test(testing.test_f1(model=wrapped_model, dataset=wrapped_data, threshold=0.7)).run()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Upload your suite to the Giskard server\n",
    "\n",
    "Upload your suite to the Giskard server to:\n",
    "* Compare models to decide which model to promote\n",
    "* Debug your tests to diagnose the issues\n",
    "* Create more domain-specific tests that are integrating business feedback\n",
    "* Share your results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Uploading the test suite will automatically save the model, dataset, tests, slicing & transformation functions inside the Giskard UI server\n",
    "# Create a Giskard client after having install the Giskard server (see documentation)\n",
    "token = \"API_TOKEN\"  # Find it in Settings in the Giskard server\n",
    "\n",
    "client = GiskardClient(\n",
    "    url=\"http://localhost:19000\",  # URL of your Giskard instance\n",
    "    token=token\n",
    ")\n",
    "\n",
    "my_project = client.create_project(\"my_project\", \"PROJECT_NAME\", \"DESCRIPTION\")\n",
    "\n",
    "# Upload to the current project ✉️\n",
    "test_suite.upload(client, \"my_project\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
