{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SMS spam classification [sklearn]\n",
    "* Binary classification of sms being spam or not.  \n",
    "* Reference: <https://www.kaggle.com/code/faressayah/natural-language-processing-nlp-for-beginners>  \n",
    "* Dataset: <https://www.kaggle.com/code/faressayah/natural-language-processing-nlp-for-beginners/input?select=spam.csv>  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9529d219d1e902ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install necessary packages"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "132733e1065808c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install nltk giskard"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78af8b1ebb27a595"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfe29a9c8a9fdd06"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Iterable\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "\n",
    "import giskard\n",
    "from giskard import Dataset, Model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T14:30:22.259571Z",
     "start_time": "2023-07-31T14:30:22.225863Z"
    }
   },
   "id": "754270c3ff1a9af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download NLTK corpus"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52da59c4f0cb3c39"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mykytaalekseiev/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T14:30:24.980992Z",
     "start_time": "2023-07-31T14:30:24.918421Z"
    }
   },
   "id": "311434994bdf65c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notebook-level settings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e26d23eb0e22a925"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Necessary for custom preprocessing function transformers.\n",
    "# sklearn.set_config(transform_output=\"pandas\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T14:30:31.743831Z",
     "start_time": "2023-07-31T14:30:31.722087Z"
    }
   },
   "id": "b1685d880c3a29f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define constants"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afa661cb92cbc49b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Constants.\n",
    "TARGET_NAME = \"label\"\n",
    "TEXT_COLUMN_NAME = \"message\"\n",
    "\n",
    "# Paths.\n",
    "DATA_DIRECTORY = os.path.join(\"..\", \"datasets\", \"sms_spam_classification_dataset\", \"spam.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T14:30:49.311916Z",
     "start_time": "2023-07-31T14:30:49.284702Z"
    }
   },
   "id": "55a3935ad8a19eec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and initially preprocess data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef0d5b2829aedef7"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f29b534c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:12:56.201446Z",
     "iopub.status.busy": "2023-02-16T22:12:56.200671Z",
     "iopub.status.idle": "2023-02-16T22:12:56.283323Z",
     "shell.execute_reply": "2023-02-16T22:12:56.281887Z"
    },
    "papermill": {
     "duration": 0.101748,
     "end_time": "2023-02-16T22:12:56.285847",
     "exception": false,
     "start_time": "2023-02-16T22:12:56.184099",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-07-31T14:30:51.029727Z",
     "start_time": "2023-07-31T14:30:50.916428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  label                                            message\n0   ham  Go until jurong point, crazy.. Available only ...\n1   ham                      Ok lar... Joking wif u oni...\n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3   ham  U dun say so early hor... U c already then say...\n4   ham  Nah I don't think he goes to usf, he lives aro...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data() -> pd.DataFrame:\n",
    "    \"\"\"Load data.\"\"\"\n",
    "    df = pd.read_csv(DATA_DIRECTORY, encoding='latin-1')\n",
    "    df.dropna(how=\"any\", inplace=True, axis=1)\n",
    "    df.columns = [TARGET_NAME, TEXT_COLUMN_NAME]\n",
    "    return df\n",
    "\n",
    "messages_df = load_data()\n",
    "messages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_label(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Change string labels to the integer encoding.\"\"\"\n",
    "    df.label = LabelEncoder().fit_transform(df.label)\n",
    "    return df\n",
    "\n",
    "messages_df = preprocess_label(messages_df)\n",
    "messages_df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c832bbf0d16c118"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train-test split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee119a620a87cfe6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b33667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:12:59.658981Z",
     "iopub.status.busy": "2023-02-16T22:12:59.658525Z",
     "iopub.status.idle": "2023-02-16T22:12:59.670509Z",
     "shell.execute_reply": "2023-02-16T22:12:59.669471Z"
    },
    "papermill": {
     "duration": 0.03499,
     "end_time": "2023-02-16T22:12:59.673230",
     "exception": false,
     "start_time": "2023-02-16T22:12:59.638240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(messages_df[[TEXT_COLUMN_NAME]], messages_df[TARGET_NAME], random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define preprocessing pipeline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26177908f2f43614"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_punctuation(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Remove punctuation from text.\"\"\"\n",
    "    df[TEXT_COLUMN_NAME] = df[TEXT_COLUMN_NAME].apply(lambda text: text.translate(str.maketrans('', '', string.punctuation)))\n",
    "    return df\n",
    "\n",
    "remove_punctuation_transformer = FunctionTransformer(remove_punctuation)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1efcb7a71d45cde3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_stop_words(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Remove stopwords from text.\"\"\"\n",
    "    _STOPWORDS = stopwords.words('english') + ['u', 'Ã¼', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure']\n",
    "\n",
    "    df[TEXT_COLUMN_NAME] = df[TEXT_COLUMN_NAME].apply(lambda text: ' '.join([word for word in text.split() if word.lower() not in _STOPWORDS]))\n",
    "    return df\n",
    "\n",
    "remove_stop_words_transformer = FunctionTransformer(remove_stop_words)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6be15596896ec9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def adapt_vectorizer_input(df: pd.DataFrame) -> Iterable:\n",
    "    \"\"\"Adapt input for the vectorizers.\n",
    "\n",
    "    The problem is that vectorizers accept iterable, not DataFrame, but Series. Thus, we need to ravel dataframe with text have input single dimension.\n",
    "    Issue reference: https://stackoverflow.com/questions/50665240/valueerror-found-input-variables-with-inconsistent-numbers-of-samples-1-3185\"\"\"\n",
    "\n",
    "    df = df.iloc[:, 0]\n",
    "    return df\n",
    "\n",
    "adapt_vectorizer_input_transformer = FunctionTransformer(adapt_vectorizer_input)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11b2bfbd50332d09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Naive Bayes model pipeline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e21e9757ae0fd44"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bac208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:13:00.512698Z",
     "iopub.status.busy": "2023-02-16T22:13:00.512267Z",
     "iopub.status.idle": "2023-02-16T22:13:00.612825Z",
     "shell.execute_reply": "2023-02-16T22:13:00.611460Z"
    },
    "papermill": {
     "duration": 0.125448,
     "end_time": "2023-02-16T22:13:00.615922",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.490474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define data preprocessor pipeline.\n",
    "preprocessor = Pipeline(steps=[\n",
    "    (\"punctuation_remover\", remove_punctuation_transformer),\n",
    "    (\"stop_words_remover\", remove_stop_words_transformer),\n",
    "    (\"text_vectorizer_adapter\", adapt_vectorizer_input_transformer),\n",
    "    ('bow', CountVectorizer()),\n",
    "    ('tfid', TfidfTransformer()),\n",
    "])\n",
    "\n",
    "# Define general pipeline with data preprocessing and model.\n",
    "pipeline_naive_bayes = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fit model.\n",
    "pipeline_naive_bayes.fit(X_train, y_train)\n",
    "y_pred_prob = pipeline_naive_bayes.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Get test metric.\n",
    "metric = metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "print(f\"Test ROC-AUC score: {metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e816488",
   "metadata": {
    "papermill": {
     "duration": 0.019578,
     "end_time": "2023-02-16T22:13:00.655711",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.636133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Logistic Regression model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define general pipeline with data preprocessing and model.\n",
    "pipeline_logistic_regression = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    (\"logistic_regression\", LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit model.\n",
    "pipeline_logistic_regression.fit(X_train, y_train)\n",
    "y_pred_prob = pipeline_logistic_regression.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Get test metric.\n",
    "metric = metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "print(f\"Test ROC-AUC score: {metric}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "984ec1ff3fd904ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wrap data and models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a8fab0c95b10fec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Wrap test dataset.\n",
    "raw_dataset = pd.concat([X_test, y_test], axis=1)\n",
    "wrapped_dataset = wrap_dataset(raw_dataset,\n",
    "                               name=\"sms_spam\",\n",
    "                               target=\"label\",\n",
    "                               column_types={\"message\": \"text\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "782f82403b2b0c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Wrap Naive-Bayes model.\n",
    "wrapped_model_naive_bayes = wrap_model(pipeline_naive_bayes,\n",
    "                                       model_type=\"classification\",\n",
    "                                       name=\"spam_classifier_naive_bayes\",\n",
    "                                       feature_names=X_test.columns,\n",
    "                                       classification_threshold=0.5)\n",
    "wrapped_model_naive_bayes.predict(wrapped_dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f58f7543b68df2d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Wrap Logistic Regression model.\n",
    "wrapped_model_logistic_regression = wrap_model(pipeline_logistic_regression,\n",
    "                                               model_type=\"classification\",\n",
    "                                               name=\"spam_classifier_logistic_regression\",\n",
    "                                               feature_names=X_test.columns,\n",
    "                                               classification_threshold=0.5)\n",
    "wrapped_model_logistic_regression.predict(wrapped_dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "272c50927fe71629"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scan models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4608cac4a2828930"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Scan Naive Bayes model.\n",
    "naive_bayes_scan = giskard.scan(wrapped_model_naive_bayes, wrapped_dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edcfbf9d0c87a35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(naive_bayes_scan)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce59a03a1ae6be6f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Scan Logistic regression model.\n",
    "logistic_regression_scan = giskard.scan(wrapped_model_logistic_regression, wrapped_dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c0a65303eafa978"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(logistic_regression_scan)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b777907c7f33dbf5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.393171,
   "end_time": "2023-02-16T22:13:02.202180",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-16T22:12:43.809009",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
