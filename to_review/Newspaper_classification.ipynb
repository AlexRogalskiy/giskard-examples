{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KV3Yqc-x0dKN"
   },
   "source": [
    "![giskard_logo.png](https://raw.githubusercontent.com/Giskard-AI/giskard/main/readme/Logo_full_darkgreen.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htCJUiaF0iW8"
   },
   "source": [
    "# About Giskard\n",
    "\n",
    "Open-Source CI/CD platform for ML teams. Deliver ML products, better & faster. \n",
    "\n",
    "*   Collaborate faster with feedback from business stakeholders.\n",
    "*   Deploy automated tests to eliminate regressions, errors & biases.\n",
    "\n",
    "üè° [Website](https://giskard.ai/)\n",
    "\n",
    "üìó [Documentation](https://docs.giskard.ai/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing `giskard` and other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install giskard torch torchdata torchtext"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gJVrEpvVoA10"
   },
   "source": [
    "\n",
    "# Text classification with the `torchtext` library\n",
    "\n",
    "In this tutorial, we build a text classifier for the [`AG_NEWS` dataset](https://pytorch.org/text/stable/datasets.html?highlight=ag_news#torchtext.datasets.AG_NEWS). The classifier will take a news headline or article and detect its category (‚ÄúWorld‚Äù, ‚ÄúSports‚Äù, ‚ÄúBusiness‚Äù, ‚ÄúSci/Tech‚Äù).\n",
    "\n",
    "We will use `torch` and the `torchtext` library for the data processing pipeline, to implement model, and train in on the `AG_NEWS` data. Then, we will show how to upload the model to Giskard to inspect and validate its performances."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "O01CE1ExoA10"
   },
   "source": [
    "## 1. Data\n",
    "\n",
    "### 1.1 Data preprocessing\n",
    "\n",
    "The ``AG_NEWS`` dataset is made of tuples containing the label (category, e.g. ‚ÄúSports‚Äù, ‚ÄúBusiness‚Äù) and text (news headline or description). Before training a ML model, we need to transform the data in a format that is easy to understand by model. A standard preprocessing pipeline consists in:\n",
    "\n",
    "- tokenize sentences to produce a list of lexical tokens\n",
    "- map each token to a numerical identifier (vocabulary)\n",
    "\n",
    "We will implement this pipeline with the utilities provided by the `torchtext` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eup4gpgVoA10",
    "ExecuteTime": {
     "end_time": "2023-06-26T12:52:55.043128Z",
     "start_time": "2023-06-26T12:52:45.503053Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "# Get the AG News data\n",
    "train_data, test_data = AG_NEWS()\n",
    "\n",
    "# Simple English tokenizer provided by torchtext\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "# Build a volcabulary from all the tokens we can find in the train data\n",
    "vocab = build_vocab_from_iterator(\n",
    "    (tokenizer(text) for _, text in train_data), specials=[\"<unk>\"]\n",
    ")\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let‚Äôs wrap the tokenization and vocabulary in a single `preprocess_text` function.\n",
    "\n",
    "We also want to preprocess the labels associated to the news. In the `AG_NEWS` dataset, texts are categorized in four classes: ‚ÄúWorld‚Äù, ‚ÄúSports‚Äù, ‚ÄúBusiness‚Äù, ‚ÄúSci/Tech‚Äù. These are represented by integer values 1, 2, 3, and 4 respectively. For easier handling, we will convert these to integer IDs going from 0 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T12:53:27.046440Z",
     "start_time": "2023-06-26T12:53:27.032377Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(raw_text):\n",
    "    return vocab(tokenizer(raw_text))\n",
    "\n",
    "\n",
    "def preprocess_label(raw_label):\n",
    "    return int(raw_label) - 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UBc0uWZLoA12"
   },
   "source": [
    "Let‚Äôs test out preprocessing on a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MEoyEKVMoA12",
    "ExecuteTime": {
     "end_time": "2023-06-26T12:53:27.956669Z",
     "start_time": "2023-06-26T12:53:27.945220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[475, 21, 5, 3390, 5297, 764]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(\"Here is a simple example!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dwLINdF3oA13"
   },
   "source": [
    "The text preprocessing pipeline converts a text string into a list of integers based on the lookup table defined in the vocabulary.\n",
    "\n",
    "::\n",
    "\n",
    "    preprocess_text('here is the an example!')\n",
    "    >>> [475, 21, 2, 30, 5297, 764]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "My6Fh7jsoA13"
   },
   "source": [
    "## 2. Implement and train the model\n",
    "\n",
    "### 2.1 Text classification model\n",
    "\n",
    "The model is composed of the [nn.EmbeddingBag](https://pytorch.org/docs/stable/nn.html?highlight=embeddingbag#torch.nn.EmbeddingBag)_ layer plus a linear layer for the classification purpose. ``nn.EmbeddingBag`` with the default mode of \"mean\" computes the mean value of a ‚Äúbag‚Äù of embeddings. Although the text entries here have different lengths, nn.EmbeddingBag module requires no padding here since the text lengths are saved in offsets.\n",
    "\n",
    "Additionally, since ``nn.EmbeddingBag`` accumulates the average across\n",
    "the embeddings on the fly, ``nn.EmbeddingBag`` can enhance the\n",
    "performance and memory efficiency to process a sequence of tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "J66cyUvKoA14",
    "ExecuteTime": {
     "end_time": "2023-06-26T12:54:00.637994Z",
     "start_time": "2023-06-26T12:54:00.629874Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded).softmax(axis=-1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Preparing the data loaders\n",
    "\n",
    "First, let‚Äôs define a custom function `collate_fn` that applied our preprocessing transformations (`preprocess_text`and `preprocess_label`), converts the data to `torch.tensor`, and groups sequences of samples in batches to be sent as input for the `TextClassificationModel` we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T12:54:04.638887Z",
     "start_time": "2023-06-26T12:54:01.697602Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "# The device we are working on (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Define how we collate data into batches that can be parsed by our model\n",
    "def collate_fn(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(preprocess_label(_label))\n",
    "        processed_text = torch.tensor(preprocess_text(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "\n",
    "# Create the datasets\n",
    "train_dataset = to_map_style_dataset(train_data)\n",
    "test_dataset = to_map_style_dataset(test_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To iterate and shuffle the data, `torch` provides a [DataLoader](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader) object (you can find a tutorial [here](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)). Here we define the dataloaders for the train, validation, and test data.\n",
    "\n",
    "We use a batch size of 64 samples. By setting `shuffle = True` in the `DataLoader` arguments, the samples will be returned in a random order when iterating over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T12:54:06.304400Z",
     "start_time": "2023-06-26T12:54:06.273470Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# We further divide the training data into a train and validation split.\n",
    "train_split, valid_split = random_split(train_dataset, [0.95, 0.05])\n",
    "\n",
    "# Prepare the data loaders\n",
    "train_dataloader = DataLoader(\n",
    "    train_split, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_split, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zgbK39d6oA14"
   },
   "source": [
    "### 2.3 Training the text classifier model\n",
    "\n",
    "We build a model with the embedding dimension of 64. The vocab size is equal to the length of the vocabulary instance. The number of classes is equal to the number of labels (1 = World, 2 = Sports, 3 = Business, 4 = Sci/Tech)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "j7x89PnVoA14",
    "ExecuteTime": {
     "end_time": "2023-06-26T12:54:07.342696Z",
     "start_time": "2023-06-26T12:54:07.264231Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_size = 64\n",
    "num_class = 4  # ‚ÄúWorld‚Äù, ‚ÄúSports‚Äù, ‚ÄúBusiness‚Äù, ‚ÄúSci/Tech‚Äù\n",
    "\n",
    "model = TextClassificationModel(vocab_size, embedding_size, num_class).to(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yYNb6sDVoA14"
   },
   "source": [
    "Let‚Äôs define the a training and evaluate helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "tnYAEF9OoA14",
    "ExecuteTime": {
     "end_time": "2023-06-26T12:54:09.181027Z",
     "start_time": "2023-06-26T12:54:09.167938Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 1\n",
    "LR = 5  # learning rate\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "\n",
    "\n",
    "def train_model(dataloader, epoch=0):\n",
    "    model.train()\n",
    "    total_acc = total_count = 0\n",
    "\n",
    "    for label, text, offset in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offset)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "\n",
    "    return total_acc / total_count\n",
    "\n",
    "\n",
    "def evaluate_model(dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    total_acc = total_count = 0\n",
    "    with torch.no_grad():\n",
    "        for label, text, offsets in dataloader:\n",
    "            predicted_label = model(text, offsets)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "\n",
    "    return total_acc / total_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T12:54:42.712939Z",
     "start_time": "2023-06-26T12:54:15.499664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 27.21s | valid accuracy    0.871 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "total_accu = None\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    train_model(train_dataloader)\n",
    "    accu_val = evaluate_model(valid_dataloader)\n",
    "\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "\n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
    "        \"valid accuracy {:8.3f} \".format(\n",
    "            epoch, time.perf_counter() - start_time, accu_val\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 59)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PaKWyDSgoA15"
   },
   "source": [
    "### 2.4 Evaluate the model on the test dataset\n",
    "\n",
    "Now that we have a trained model, let‚Äôs evaluate its performances on the test data that we excluded from training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Uy9ziVhloA15",
    "ExecuteTime": {
     "end_time": "2023-06-26T12:54:46.575852Z",
     "start_time": "2023-06-26T12:54:45.901101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy    0.869\n"
     ]
    }
   ],
   "source": [
    "accu_test = evaluate_model(test_dataloader)\n",
    "\n",
    "print('Test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LTtEOI_7oA15"
   },
   "source": [
    "We can see an example of classification, by using our model to predict the category of a golf news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "OqLsJeQGoA15",
    "ExecuteTime": {
     "end_time": "2023-06-26T12:54:48.617625Z",
     "start_time": "2023-06-26T12:54:48.601279Z"
    }
   },
   "outputs": [],
   "source": [
    "news_labels = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tech\"}\n",
    "\n",
    "\n",
    "def label_to_text(label_id: int):\n",
    "    return news_labels[label_id]\n",
    "\n",
    "\n",
    "def predict(text):\n",
    "    \"\"\"Given a text it predicts its category.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(preprocess_text(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T12:54:49.881025Z",
     "start_time": "2023-06-26T12:54:49.867733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Sports news!\n"
     ]
    }
   ],
   "source": [
    "example_news = (\n",
    "    \"MEMPHIS, Tenn. ‚Äì Four days ago, Jon Rahm was \"\n",
    "    \"enduring the season‚Äôs worst weather conditions on Sunday at The \"\n",
    "    \"Open on his way to a closing 75 at Royal Portrush, which \"\n",
    "    \"considering the wind and the rain was a respectable showing. \"\n",
    "    \"Thursday‚Äôs first round at the WGC-FedEx St. Jude Invitational \"\n",
    "    \"was another story. With temperatures in the mid-80s and hardly any \"\n",
    "    \"wind, the Spaniard was 13 strokes better in a flawless round. \"\n",
    "    \"Thanks to his best putting performance on the PGA Tour, Rahm \"\n",
    "    \"finished with an 8-under 62 for a three-stroke lead, which \"\n",
    "    \"was even more impressive considering he‚Äôd never played the \"\n",
    "    \"front nine at TPC Southwind.\"\n",
    ")\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "predicted = predict(example_news)\n",
    "\n",
    "print(f\"This is a {label_to_text(predicted)} news!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect the external worker in daemon mode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JQOB4tgkysCm"
   },
   "source": [
    "## 3. Inspect the model with Giskard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Start the Giskard worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!giskard worker start -d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create a Giskard project via the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from giskard import GiskardClient\n",
    "\n",
    "GISKARD_URL = \"http://localhost:9000\"  # if Giskard is installed locally (see: https://docs.giskard.ai/start/guides/installation)\n",
    "GISKARD_API_TOKEN = \"YOUR_GISKARD_TOKEN\"  # you can generate your API token in the settings of the Giskard application\n",
    "\n",
    "client = GiskardClient(GISKARD_URL, GISKARD_API_TOKEN)\n",
    "\n",
    "# Create a Giskard project if it does not exist\n",
    "if \"news_classification_demo\" in [p.project_key for p in client.list_projects()]:\n",
    "    project = client.get_project(\"news_classification_demo\")\n",
    "else:\n",
    "    project = client.create_project(\n",
    "        project_key=\"news_classification_demo\", name=\"News text classification\"\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to pack the dataset in a format recognized by Giskard, using the `giskard.Dataset` class. This is easy, since a Giskard dataset can be created from standard `pandas.DataFrame` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "xNjXaNvWzsoT"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fears for T N pension after talks Unions repre...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP) ...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prediction Unit Helps Forecast Wildfires (AP) ...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP) AP...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  Fears for T N pension after talks Unions repre...  Business\n",
       "1  The Race is On: Second Private Team Sets Launc...  Sci/Tech\n",
       "2  Ky. Company Wins Grant to Study Peptides (AP) ...  Sci/Tech\n",
       "3  Prediction Unit Helps Forecast Wildfires (AP) ...  Sci/Tech\n",
       "4  Calif. Aims to Limit Farm-Related Smog (AP) AP...  Sci/Tech"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Our data in a dataframe format\n",
    "df = pd.DataFrame(\n",
    "    {\"text\": text, \"label\": label_to_text(label_id)} for label_id, text in test_data\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully uploaded to project key 'news_classification_demo' with ID = d61d7470-52ee-4101-a34f-7a3f3f723b7b\n"
     ]
    }
   ],
   "source": [
    "from giskard import Dataset\n",
    "\n",
    "# Create the Giskard dataset\n",
    "dataset = Dataset(df, name=\"Test Dataset\", target=\"label\", feature_types={\"text\": \"text\", \"label\": \"category\"})\n",
    "dataset_id = dataset.upload(client, project.project_key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Head over to the Giskard app to check your newly uploaded dataset!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To let Giskard work with our model, we need to tell it how to transform the dataset we just uploaded to a format that the model can handle. To do that, we specify a `dataframe_to_torch_dataset` function that will take the data from Giskard and convert it to a `torch.utils.data.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset as TorchDataset\n",
    "\n",
    "def dataframe_to_torch_dataset(df: pd.DataFrame) -> TorchDataset:\n",
    "    \"\"\"Returns `(preprocessed_text, offset)` as torch tensors.\"\"\"\n",
    "    return to_map_style_dataset((torch.tensor(preprocess_text(text)), torch.tensor([0])) for text in df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "OnQKNsE8zmA4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully uploaded to project key 'news_classification_demo' with ID = 2cee75ca-2c1a-49d8-aeff-9c63c7fba106\n"
     ]
    }
   ],
   "source": [
    "from giskard import Model\n",
    "import numpy as np\n",
    "\n",
    "giskard_model = Model(\n",
    "    clf=model,\n",
    "    name=\"SimpleNewsClassificationModel\",\n",
    "    feature_names=[\"text\"],\n",
    "    model_type=\"classification\",\n",
    "    classification_labels=list(news_labels.values()),\n",
    "    data_preprocessing_function=dataframe_to_torch_dataset,\n",
    ")\n",
    "\n",
    "# Create a small slice of the dataset to validate that our model works fine before uploading it to Giskard.\n",
    "validate_ds = dataset.slice(lambda x: x.head())\n",
    "\n",
    "model_id = giskard_model.upload(client, \"news_classification_demo\", validate_ds=validate_ds)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
