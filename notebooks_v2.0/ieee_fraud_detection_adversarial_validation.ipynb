{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# IEEE Fraud detection adversarial validation [sklearn, lgbm]\n",
    "* IEEE Fraud detection train/test data binary classification task.\n",
    "* Reference notebook: <https://www.kaggle.com/code/jtrotman/ieee-fraud-adversarial-lgb-split-points/notebook>\n",
    "* Dataset: <https://www.kaggle.com/code/jtrotman/ieee-fraud-adversarial-lgb-split-points/input>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Quickstart\n",
    "\n",
    "By running this notebook, you’ll create a whole test suite in a few lines of code. The model used here is a LGBM classification model with the IEEE fraud detection dataset. Feel free to use your own model (tabular, text, or LLM).\n",
    "\n",
    "You’ll learn how to:\n",
    "* Detect vulnerabilities by scanning the model\n",
    "* Generate a test suite with domain-specific tests\n",
    "* Customize your test suite by loading a test from the Giskard catalog\n",
    "* Upload your model to the Giskard server to:\n",
    "* Compare models to decide which one to promote\n",
    "* Debug your tests to diagnose issues\n",
    "* Share your results and collect business feedback from your team"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install Giskard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install giskard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from pandas.api.types import union_categoricals\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import giskard\n",
    "from giskard import GiskardClient, testing\n",
    "from giskard import Dataset, Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Constants.\n",
    "TARGET_COLUMN = 'isTest'\n",
    "IDX_LABEL = 'TransactionID'\n",
    "\n",
    "# Paths.\n",
    "DATA_URL = os.path.join(\"ftp://sys.giskard.ai\", \"pub\", \"unit_test_resources\", \"fraud_detection_classification_dataset\", \"{}\")\n",
    "DATA_PATH = Path.home() / \".giskard\" / \"fraud_detection_classification_dataset\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data loading and preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fetch_from_ftp(url: str, file: Path) -> None:\n",
    "    \"\"\"Helper to fetch data from the FTP server.\"\"\"\n",
    "    if not file.parent.exists():\n",
    "        file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if not file.exists():\n",
    "        print(f\"Downloading data from {url}\")\n",
    "        urlretrieve(url, file)\n",
    "\n",
    "    print(f\"Data was loaded!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fetch_dataset():\n",
    "    files_to_fetch = [\"train_transaction.csv\", \"train_identity.csv\", \"test_transaction.csv\", \"test_identity.csv\"]\n",
    "    for file_name in files_to_fetch:\n",
    "        fetch_from_ftp(DATA_URL.format(file_name), DATA_PATH / file_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define data-types of transactions features.\n",
    "DATA_TYPES_TRANSACTION = {\n",
    "    'TransactionID': 'int32',\n",
    "    'isFraud': 'int8',\n",
    "    'TransactionDT': 'int32',\n",
    "    'TransactionAmt': 'float32',\n",
    "    'ProductCD': 'category',\n",
    "    'card1': 'int16',\n",
    "    'card2': 'float32',\n",
    "    'card3': 'float32',\n",
    "    'card4': 'category',\n",
    "    'card5': 'float32',\n",
    "    'card6': 'category',\n",
    "    'addr1': 'float32',\n",
    "    'addr2': 'float32',\n",
    "    'dist1': 'float32',\n",
    "    'dist2': 'float32',\n",
    "    'P_emaildomain': 'category',\n",
    "    'R_emaildomain': 'category',\n",
    "}\n",
    "\n",
    "C_COLS = [f'C{i}' for i in range(1, 15)]\n",
    "D_COLS = [f'D{i}' for i in range(1, 16)]\n",
    "M_COLS = [f'M{i}' for i in range(1, 10)]\n",
    "V_COLS = [f'V{i}' for i in range(1, 340)]\n",
    "\n",
    "DATA_TYPES_TRANSACTION.update((c, 'float32') for c in C_COLS)\n",
    "DATA_TYPES_TRANSACTION.update((c, 'float32') for c in D_COLS)\n",
    "DATA_TYPES_TRANSACTION.update((c, 'float32') for c in V_COLS)\n",
    "DATA_TYPES_TRANSACTION.update((c, 'category') for c in M_COLS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define datatypes of identity features.\n",
    "DATA_TYPES_ID = {\n",
    "    'TransactionID': 'int32',\n",
    "    'DeviceType': 'category',\n",
    "    'DeviceInfo': 'category',\n",
    "}\n",
    "\n",
    "ID_COLS = [f'id_{i:02d}' for i in range(1, 39)]\n",
    "ID_CATS = [\n",
    "    'id_12', 'id_15', 'id_16', 'id_23', 'id_27', 'id_28', 'id_29', 'id_30',\n",
    "    'id_31', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38'\n",
    "]\n",
    "\n",
    "DATA_TYPES_ID.update(((c, 'float32') for c in ID_COLS))\n",
    "DATA_TYPES_ID.update(((c, 'category') for c in ID_CATS))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define list of all categorical features.\n",
    "CATEGORICALS = [f_name for (f_name, f_type) in dict(DATA_TYPES_TRANSACTION, **DATA_TYPES_ID).items() if f_type == \"category\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_set(_type):\n",
    "    \"\"\"Read both transactions and identity data.\"\"\"\n",
    "    print(f\"Reading transactions data...\")\n",
    "    _df = pd.read_csv(os.path.join(DATA_PATH, f'{_type}_transaction.csv'),\n",
    "                      index_col=IDX_LABEL, dtype=DATA_TYPES_TRANSACTION, nrows=250)\n",
    "\n",
    "    print(f\"Reading identity data...\")\n",
    "    _df = _df.join(pd.read_csv(os.path.join(DATA_PATH, f'{_type}_identity.csv'),\n",
    "                               index_col=IDX_LABEL, dtype=DATA_TYPES_ID))\n",
    "    return _df\n",
    "\n",
    "def read_dataset():\n",
    "    \"\"\"Read whole data.\"\"\"\n",
    "\n",
    "    fetch_dataset()\n",
    "\n",
    "    print(f\"Reading train data...\")\n",
    "    train_set = read_set('train')\n",
    "\n",
    "    print(f\"Reading test data...\")\n",
    "    test_set = read_set('test')\n",
    "\n",
    "    return train_set, test_set\n",
    "\n",
    "def preprocess_dataset(train_set, test_set):\n",
    "    \"\"\"Unite train and test into common dataframe.\"\"\"\n",
    "    # Create a new target column and remove a former one from the train data.\n",
    "    print(\"Start data preprocessing...\")\n",
    "    train_set.pop('isFraud')\n",
    "    train_set['isTest'] = 0\n",
    "    test_set['isTest'] = 1\n",
    "\n",
    "    # Preprocess categorical features.\n",
    "    n_train = train_set.shape[0]\n",
    "    for c in train_set.columns:\n",
    "        s = train_set[c]\n",
    "        if hasattr(s, 'cat'):\n",
    "            u = union_categoricals([train_set[c], test_set[c]], sort_categories=True)\n",
    "            train_set[c] = u[:n_train]\n",
    "            test_set[c] = u[n_train:]\n",
    "\n",
    "    # Unite train and test data.\n",
    "    united = pd.concat([train_set, test_set])\n",
    "\n",
    "    # Add additional features.\n",
    "    united['TimeInDay'] = united.TransactionDT % 86400\n",
    "    united['Cents'] = united.TransactionAmt % 1\n",
    "\n",
    "    # Remove useless columns.\n",
    "    united.drop(\"TransactionDT\", axis=1, inplace=True)\n",
    "\n",
    "    print(f\"Dataset merged and preprocessed! Resulted shape: {united.shape}\")\n",
    "\n",
    "    return united"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "united_dataset = preprocess_dataset(*read_dataset())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train-test split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(united_dataset.drop(TARGET_COLUMN, axis=1), united_dataset[TARGET_COLUMN], test_size=0.25)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wrap test dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_dataset = pd.concat([X_test, y_test], axis=1)\n",
    "wrapped_dataset = Dataset(raw_dataset,\n",
    "                          name=\"fraud_detection_adversarial_dataset\",\n",
    "                          target=TARGET_COLUMN,\n",
    "                          cat_columns=CATEGORICALS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare estimator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define parameters of an estimator.\n",
    "ESTIMATOR_PARAMS = {\n",
    "    'num_leaves': 64,\n",
    "    'objective': 'binary',\n",
    "    'min_data_in_leaf': 10,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_freq': 1,\n",
    "    'max_cat_to_onehot': 128,\n",
    "    'metric': 'auc',\n",
    "    'n_jobs': -1,\n",
    "    'seed': 42,\n",
    "    'subsample_for_bin': united_dataset.shape[0]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "estimator = LGBMClassifier(**ESTIMATOR_PARAMS)\n",
    "estimator.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_metric = roc_auc_score(y_train, estimator.predict_proba(X_train)[:, 1].T)\n",
    "test_metric = roc_auc_score(y_test, estimator.predict_proba(X_test)[:, 1].T)\n",
    "\n",
    "print(f\"Train ROC-AUC score: {train_metric:.2f}\")\n",
    "print(f\"Test ROC-AUC score: {test_metric:.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wrap estimator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prediction_function(df: pd.DataFrame) -> np.ndarray:\n",
    "    return estimator.predict_proba(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wrapped_model = Model(prediction_function,\n",
    "                      model_type=\"classification\",\n",
    "                      name=\"train_test_data_classifier\",\n",
    "                      feature_names=X_train.columns,\n",
    "                      classification_threshold=0.5,\n",
    "                      classification_labels=[0, 1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Validate wrapped model.\n",
    "wrapped_test_metric = roc_auc_score(y_test, wrapped_model.predict(wrapped_dataset).raw[:, 1].T)\n",
    "print(f\"Wrapped Test ROC-AUC score: {wrapped_test_metric:.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scan your model to find vulnerabilities\n",
    "With the Giskard scan feature, you can detect vulnerabilities in your model, including performance biases, unrobustness, data leakage, stochasticity, underconfidence, ethical issues, and more. For detailed information about the scan feature, please refer to our scan documentation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = giskard.scan(wrapped_model, wrapped_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate a test suite from the Scan\n",
    "The objects produced by the scan can be used as fixtures to generate a test suite that integrate domain-specific issues. To create custom tests, refer to the Test your ML Model page."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_suite = results.generate_test_suite(\"My first test suite\")\n",
    "test_suite.run()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Customize your suite by loading objects from the Giskard catalog\n",
    "\n",
    "The Giskard open source catalog will enable to load:\n",
    "* Tests such as metamorphic, performance, prediction & data drift, statistical tests, etc\n",
    "* Slicing functions such as detectors of toxicity, hate, emotion, etc\n",
    "* Transformation functions such as generators of typos, paraphrase, style tune, etc\n",
    "\n",
    "For demo purposes, we will load a simple unit test (test_f1) that checks if the test F1 score is above the given threshold. For more examples of tests and functions, refer to the Giskard catalog."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_suite.add_test(testing.test_f1(model=wrapped_model, dataset=wrapped_dataset, threshold=0.7)).run()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Upload your suite to the Giskard server\n",
    "\n",
    "Upload your suite to the Giskard server to:\n",
    "* Compare models to decide which model to promote\n",
    "* Debug your tests to diagnose the issues\n",
    "* Create more domain-specific tests that are integrating business feedback\n",
    "* Share your results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Uploading the test suite will automatically save the model, dataset, tests, slicing & transformation functions inside the Giskard UI server\n",
    "# Create a Giskard client after having install the Giskard server (see documentation)\n",
    "token = \"API_TOKEN\"  # Find it in Settings in the Giskard server\n",
    "\n",
    "client = GiskardClient(\n",
    "    url=\"http://localhost:19000\",  # URL of your Giskard instance\n",
    "    token=token\n",
    ")\n",
    "\n",
    "my_project = client.create_project(\"my_project\", \"PROJECT_NAME\", \"DESCRIPTION\")\n",
    "\n",
    "# Upload to the current project ✉️\n",
    "test_suite.upload(client, \"my_project\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
