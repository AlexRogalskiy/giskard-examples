{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Amazon reviews classification [sklearn]\n",
    "* Binary classification of product's review 'helpfulness' (quality).\n",
    "* Reference notebook: <https://t-lanigan.github.io/amazon-review-classifier/>\n",
    "* Dataset: <http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Apps_for_Android_5.json.gz>\n",
    "\n",
    "By running this notebook, you’ll create a whole test suite in a few lines of code. The model used here is a simple classification model with the Amazon reviews dataset. Feel free to use your own model (tabular, text, or LLM).\n",
    "\n",
    "You’ll learn how to:\n",
    "* Detect vulnerabilities by scanning the model\n",
    "* Generate a test suite with domain-specific tests\n",
    "* Customize your test suite by loading a test from the Giskard catalog\n",
    "* Upload your model to the Giskard server to:\n",
    "    * Compare models to decide which one to promote\n",
    "    * Debug your tests to diagnose issues\n",
    "    * Share your results and collect business feedback from your team"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install Giskard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install giskard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from urllib.request import urlretrieve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import giskard\n",
    "from giskard import Dataset, Model, GiskardClient, testing\n",
    "\n",
    "# Disable chained assignment warning.\n",
    "pd.options.mode.chained_assignment = None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants.\n",
    "RANDOM_SEED = 0\n",
    "TEST_RATIO = 0.2\n",
    "\n",
    "TARGET_THRESHOLD = 0.5\n",
    "TARGET_NAME = \"isHelpful\"\n",
    "\n",
    "# Paths.\n",
    "DATA_URL = os.path.join(\"ftp://sys.giskard.ai\", \"pub\", \"unit_test_resources\", \"amazon_review_dataset\", \"reviews.json\")\n",
    "DATA_PATH = Path.home() / \".giskard\" / \"amazon_review_dataset\" / \"reviews.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load and preprocess data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fetch_from_ftp(url: str, file: Path) -> None:\n",
    "    \"\"\"Helper to fetch data from the FTP server.\"\"\"\n",
    "    if not file.parent.exists():\n",
    "        file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if not file.exists():\n",
    "        print(f\"Downloading data from {url}\")\n",
    "        urlretrieve(url, file)\n",
    "\n",
    "    print(f\"Data was loaded!\")\n",
    "\n",
    "\n",
    "def download_data(**kwargs) -> pd.DataFrame:\n",
    "    \"\"\"Download the dataset using URL.\"\"\"\n",
    "    fetch_from_ftp(DATA_URL, DATA_PATH)\n",
    "    _df = pd.read_json(DATA_PATH, lines=True, **kwargs)\n",
    "    return _df\n",
    "\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Perform data-preprocessing steps.\"\"\"\n",
    "    print(f\"Start data preprocessing...\")\n",
    "\n",
    "    # Select columns.\n",
    "    df = df[[\"reviewText\", \"helpful\"]]\n",
    "\n",
    "    # Remove Null-characters (x00) from the dataset.\n",
    "    df.reviewText = df.reviewText.apply(lambda x: x.replace(\"\\x00\", \"\"))\n",
    "\n",
    "    # Extract numbers of helpful and total votes.\n",
    "    df['helpful_ratings'] = df.helpful.apply(lambda x: x[0])\n",
    "    df['total_ratings'] = df.helpful.apply(lambda x: x[1])\n",
    "\n",
    "    # Filter unreasonable comments.\n",
    "    df = df[df.total_ratings > 10]\n",
    "\n",
    "    # Create target column.\n",
    "    df[TARGET_NAME] = np.where((df.helpful_ratings / df.total_ratings) > TARGET_THRESHOLD, 1, 0).astype(int)\n",
    "\n",
    "    # Delete columns we don't need anymore.\n",
    "    df.drop(columns=[\"helpful\", 'helpful_ratings', 'total_ratings'], inplace=True)\n",
    "\n",
    "    print(\"Data preprocessing finished!\")\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = download_data(nrows=20000)\n",
    "reviews_df = preprocess_data(reviews_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train-test split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews_df[[\"reviewText\"]], reviews_df[TARGET_NAME],\n",
    "                                                    test_size=TEST_RATIO, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap dataset with Giskard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.concat([X_test, y_test], axis=1)\n",
    "wrapped_data = Dataset(raw_data, name=\"reviews\", target=TARGET_NAME, column_types={\"reviewText\": \"text\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define preprocessing pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(x):\n",
    "    \"\"\"Remove punctuation from input string.\"\"\"\n",
    "    x = x.reviewText.apply(lambda row: row.translate(str.maketrans('', '', string.punctuation)))\n",
    "    return x\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "    (\"punctuation\", FunctionTransformer(remove_punctuation)),\n",
    "    (\"vectorizer\", TfidfVectorizer(stop_words='english', min_df=0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimator\", LogisticRegression(random_state=RANDOM_SEED))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "train_metric = roc_auc_score(y_train, pipeline.predict_proba(X_train)[:, 1])\n",
    "test_metric = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"Train ROC-AUC score: {train_metric:.2f}\")\n",
    "print(f\"Test ROC-AUC score: {test_metric:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap model with Giskard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model = Model(model=pipeline.predict_proba,\n",
    "                      model_type=\"classification\",\n",
    "                      feature_names=[\"reviewText\"],\n",
    "                      name=\"review_helpfulness_predictor\",\n",
    "                      classification_threshold=0.5,\n",
    "                      classification_labels=[0, 1])\n",
    "\n",
    "# Validate wrapped model.\n",
    "wrapped_predict = wrapped_model.predict(wrapped_data).raw[:, 1]\n",
    "wrapped_test_metric = roc_auc_score(y_test, wrapped_predict)\n",
    "\n",
    "print(f\"Wrapped Test ROC-AUC score: {wrapped_test_metric:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan your model to find vulnerabilities\n",
    "With the Giskard scan feature, you can detect vulnerabilities in your model, including performance biases, unrobustness, data leakage, stochasticity, underconfidence, ethical issues, and more. For detailed information about the scan feature, please refer to our scan documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = giskard.scan(model=wrapped_model, dataset=wrapped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate a test suite from the Scan\n",
    "The objects produced by the scan can be used as fixtures to generate a test suite that integrate domain-specific issues. To create custom tests, refer to the Test your ML Model page."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_suite = results.generate_test_suite(\"My first test suite\")\n",
    "test_suite.run()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Customize your suite by loading objects from the Giskard catalog\n",
    "\n",
    "The Giskard open source catalog will enable to load:\n",
    "* Tests such as metamorphic, performance, prediction & data drift, statistical tests, etc\n",
    "* Slicing functions such as detectors of toxicity, hate, emotion, etc\n",
    "* Transformation functions such as generators of typos, paraphrase, style tune, etc\n",
    "\n",
    "For demo purposes, we will load a simple unit test (test_f1) that checks if the test F1 score is above the given threshold. For more examples of tests and functions, refer to the Giskard catalog."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_suite.add_test(testing.test_f1(model=wrapped_model, dataset=wrapped_data, threshold=0.7)).run()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload your suite to the Giskard server\n",
    "\n",
    "Upload your suite to the Giskard server to:\n",
    "* Compare models to decide which model to promote\n",
    "* Debug your tests to diagnose the issues\n",
    "* Create more domain-specific tests that are integrating business feedback\n",
    "* Share your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading the test suite will automatically save the model, dataset, tests, slicing & transformation functions inside the Giskard UI server\n",
    "# Create a Giskard client after having install the Giskard server (see documentation)\n",
    "token = \"API_TOKEN\"  # Find it in Settings in the Giskard server\n",
    "\n",
    "client = GiskardClient(\n",
    "    url=\"http://localhost:19000\",  # URL of your Giskard instance\n",
    "    token=token\n",
    ")\n",
    "\n",
    "my_project = client.create_project(\"my_project\", \"PROJECT_NAME\", \"DESCRIPTION\")\n",
    "\n",
    "# Upload to the current project ✉️\n",
    "test_suite.upload(client, \"my_project\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
